[
  {
    "objectID": "planning-for-submission.html",
    "href": "planning-for-submission.html",
    "title": "Planning for submission",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#quality-control-of-dnarna",
    "href": "planning-for-submission.html#quality-control-of-dnarna",
    "title": "Planning for submission",
    "section": "Quality control of DNA/RNA",
    "text": "Quality control of DNA/RNA\nYour DNA or RNA samples will need to pass certain quality cut-offs for sequencing, which the sequencing facility will ask for and will have thresholds they require upon submission (e.g., see the Otago Genomics Facility requirements here). After you have done your extractions in the lab, you should perform QC with:\n\nA spectrophotometer (e.g., NanoDrop, DeNovix), which will give you a good indication of the purity/contamination of your sample through 260/280 and 260/230 ratios. This method is not very reliable for determining concentration of your nucleic acid.\nA fluorescent-based quantification method (e.g., Qubit), which will give you a very accurate indication of concentration of your nucleic acid (but not of any contaminants).\nA fragment analysis instrument (e.g., Agilent 2100 Bioanalyzer, Agilent 5300 Fragment Analyzer or Agilent TapeStation), which you can think of like a high-tech agarose gel. It will give you a good indication of your 28S/18S ratio for RNA (this is used to determine the overall RIN - RNA integrity number*) or your fragment size distribution for DNA.\n\nTogether, these will give you an almost complete picture of your sample, ready for sequencing. Note that if your samples are below threshold quality, there are library prep protocols that can allow for lower quality or degraded samples. Ideally, this should only be done if there is no option to re-extract, re-purify or repeat the experiment.\n\n*RNA integrity number: note that for some protosome species (e.g., molluscs, arthropods) the 28S rRNA subunit has a hidden break, which can negatively affect the RIN calculation. This results in the quality of the RNA appearing to be is worse than it actually is.",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#sequencing-libraries",
    "href": "planning-for-submission.html#sequencing-libraries",
    "title": "Planning for submission",
    "section": "Sequencing libraries",
    "text": "Sequencing libraries\nThe first thing that needs to be done for Illumina, PacBio or Oxford Nanopore (ONT) sequencing is to turn the DNA or RNA sample into something called a library. This converts the raw nucleic acids into a form that the sequencer can actually read. This is generally done by the technician that will also sequence your samples, but some labs may do library prep in-house (i.e., you may do it yourself!). For Illumina and PacBio, RNA is first converted into DNA during the library prep process. ONT is a little different, in that it can sequence native RNA directly, with minimal prep before sequencing. DNA library preparation for ONT sequencing is also generally simpler than for Illumina and PacBio. This is because the technology used to sequence the DNA/RNA using ONT is quite different to how Illumina and PacBio achieve it‚Äìmore on that in the next section on flow cells and sequencing platforms 101\n\n\n\n\n\n\nIllumina lib prep molecular workflow diagram\n\n\n\n\n\n\n\n\n\nLibrary preparation (for Illumina and PacBio) generally involves the following steps, and takes 1-2 days in the lab:\n\n(Optional) Target enrichment / RNA selection\nSelectively enriching for your target molecule (e.g., for standard RNAseq you likely will do polyA capture).\n\n(RNAseq only) Converting your RNA into cDNA using reverse transcriptase.\n\nFragmentation (if needed) Some kits fragment RNA before reverse transcription, others fragment cDNA/DNA after.\nThis ensures fragments are the right size for the platform (e.g., ~200‚Äì400 bp for Illumina).\nEnd repair and A-tailing\nEnds are cleaned up so adapters can be ligated efficiently.\nAdapter ligation\nAdapters are short sequences that enable library binding to the flow cell (Illumina) or capture for SMRTbells (PacBio).\nSome kits combine this with indexing.\n\n\n\n\n\n\n\nPacBio lib prep - SMRTbell adapters\n\n\n\n\n\n\nNote: the SMRTbell technology allows HiFi (high fidelity) long read sequencing. The DNA becomes circularised, which allows the polymerase to make repeated passes around the DNA and the consensus sequence therefore has a higher accuracy than single pass sequencing.\n\n\n\n\nIndexing (barcoding)\nIndices allow multiple samples to be pooled together and sequenced on the same flow cell, then computationally separated afterward (called mulitplexing and demultiplexing).\nSize selection / cleanup\nTypically done with magnetic beads to remove adapter dimers and select the desired fragment range.\nLibrary amplification (if required)\nSome protocols use PCR to enrich adapter-ligated molecules; others (e.g., some PacBio) are PCR-free.\nFinal QC and quantification\nUsing Qubit, Bioanalyzer/Tapestation/Fragment Analyzer, etc. This step ensures your library meets sequencing requirements.\n\n\n\n\n\n\n\nBioanalyzer trace of final library (Illumina mRNA lib prep)\n\n\n\n\n\n\nWhat do you think the two large narrow peaks are around 15 bp and 1500bp?\n\n\n\n\n\n\nSOLUTION\n\n\n\n\n\nThe two narrow peaks are ladder sequence. These are internal standards of known size we add in for quality control. These can also be used for concentration estimation, but fluorescence-based quantification (e.g., Qubit) is more accurate.\n\n\n\n\n\n\n\n\nThere are different library prep methods (i.e., protocols) for each platform that you will need to chose. This will depend on a few things, such as:\n\nThe quality of your RNA/DNA (e.g., high-quality RNA allows polyA selection; degraded samples may require ribo-depletion or specialised kits).\n\nThe species/tissue type you extracted your RNA/DNA from (e.g., plants have rRNA types that require plant-specific depletion kits, some tissues have high mitochondrial RNA content).\n\nThe type of analysis you want to do i.e., what is your research question\n\nFor example, if you are doing a ‚Äòstandard‚Äô Illumina RNA sequencing project (e.g,. you plan to do differential gene expression analysis to compare different samples), a common choice is Illumina stranded mRNA library prep, which uses polyA selection to capture mRNA. However, you may chose Illumina total RNA library prep with ribo-depletion, which is more expensive, but it has some advantages such as: it can capture non-polyadenylated RNAs (more comprehensive RNA profile) and and is a better option if your samples are partially degraded (it can also handle FFPE samples).\n\nDISCUSSION üí¨\n\n\n\n\n\n\nWhy do you think polyA capture is used for ‚Äòstandard‚Äô RNAseq?\n\n\n\n\n\nMature mRNAs have polyA tails, which can be selectively isolated using oligo DT coated beads that bind mature RNAs only. All other non-polyadenylated nucleic acids and cellular debris can then be washed away.\n\n\n\n\n\n\n\n\n\nWhy do you think we bother adding ‚Äúindex‚Äù sequences to libraries at all? Why not sequence each sample separately?\n\n\n\n\n\nIndexing (barcoding) allows multiple samples to be pooled in a single sequencing run. This massively reduces cost and time. Because each library carries a unique index, they can be mixed (i.e., pooled) together and sequenced simultaneously, and downstream software can computationally separate (demultiplex) them accurately afterward.\n\n\n\n\n\n\n\n\n\nWhy do you think size selection is such an important step? What would happen if we skipped it?\n\n\n\n\n\nSize selection ensures that fragments fall within the size range the sequencer expects. Without it, you may get:\n\nleftover adapter dimers (which waste sequencing reads as they take up ‚Äòreal estate‚Äô on the flow cell)\ntoo-short fragments (which cluster preferentially, causing over-representation and distorts the data e.g., sequencing may read into adapters or flow cell)\n\ntoo-long fragments (which may not fully sequence or reduce yield)\n\n\n\n\n\n\n\nHow do I know if I have things like adapter dimers in the final library??\n\n\n\n\n\nThe final fragment analysis (e.g., Bioanalyzer) trace of the library will show you. See below a picture of a trace with adapter dimers present (~120-150bp peak).\nTip: You can repeat the final wash step in the library prep protocol to remove adapter dimers and re-run Bioanalyzer to confirm. Sometimes a very small peak will still be present which will not overly affect the run (you can see one on the previous image above!)\n Image from Illumina general knowledge base",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#flow-cells-and-sequencing-platforms-101",
    "href": "planning-for-submission.html#flow-cells-and-sequencing-platforms-101",
    "title": "Planning for submission",
    "section": "Flow cells and sequencing platforms 101",
    "text": "Flow cells and sequencing platforms 101\nThe three major sequencing platform and consumables companies are Illumina, PacBio (Pacific Biosystems) and Oxford Nanopore Technologies (ONT). Each make different platforms/instruments that can handle different levels of throughput, but the chemistry and the ‚Äòreading‚Äô of the sequencing is the main point of difference between the three companies.\nA few examples of the different platforms are:\nIllumina\n\nMiSeq i100\nNextSeq 550 / 1000 / 2000\nNovaSeq 6000 / X\n\nPacBio\n\nSequel II\n\nRevio\n\nOxford Nanopore Technologies\n\nMinION\n\nGridION\n\nPromethION\n\nA flow cell is the physical surface inside the sequencing machine (or platform) where the actual reading of DNA or RNA occurs. There are different sizes you can chose from, depending on how many reads you need. Although Illumina, PacBio, and ONT all call their consumables ‚Äúflow cells,‚Äù the underlying technologies are very different.\nFor the most part, and in-depth knowledge of how these flow cells work is not needed to get you started with your sequencing project.\nHere are the major differences:\n\n\n\n\n\n\n\n\n\nFeature\nIllumina\nPacBio (HiFi / SMRT)\nOxford Nanopore (ONT)\n\n\n\n\nHow sequencing works\nSequencing-by-synthesis (fluorescent nucleotides added one base at a time)\nSingle-molecule real-time sequencing (polymerase incorporates fluorescent bases inside ZMWs)\nNanopore sensing (changes in ionic current as DNA/RNA passes through a pore)\n\n\nFlow cell structure\nPatterned flow cell with billions of oligos that form clonal clusters\nSMRT Cell containing millions of Zero-Mode Waveguides (ZMWs)\nMembrane embedded with thousands of protein nanopores\n\n\nWhat binds to the flow cell\nLibraries bind via adapters to oligos ‚Üí amplified into clusters\nA single SMRTbell + polymerase complex loads into each ZMW\nDNA or RNA strand with a motor protein threads into a nanopore\n\n\nSignal detected\nFluorescent signal imaged each cycle\nFluorescent flashes when each base is incorporated\nChanges in electrical current across the pore\n\n\nAmplification?\nYes ‚Äî cluster generation required\nNo ‚Äî true single-molecule reads\nNo (PCR-free), though can use PCR in library prep\n\n\nTypical read length\n100‚Äì300 bp\n10‚Äì25 kb HiFi reads\n10 kb to &gt;100 kb (ultra-long &gt;1 Mb possible)\n\n\nCan sequence native RNA?\nNo ‚Äî convert to cDNA library\nNo ‚Äî convert to cDNA library\nYes ‚Äî direct RNA sequencing\n\n\nStrengths\nHigh accuracy, high throughput, cost-efficient, chemistry highly compatible with different species/tissues\nHighly accurate long reads; excellent for haplotype resolution\nUltra-long reads; portable; real-time analysis; can detect base mods\n\n\nLimitations\nShort reads only\nLower throughput than Illumina; expensive\nHigher raw error rate; pore lifetime limits yield and susceptible to clogging\n\n\nBest used for\nStandard RNA-seq (DGE); de novo transcriptomes; high-depth short-read assays; metagenomics; error-correcting long reads\nGenome assembly (chromosome-level with HiFi); full-length RNA (Iso-Seq for isoforms); structural variant detection\nField-based sequencing (e.g, rapid microbial identification); genome assembly; native RNA including modification detection (e.g., methylation)",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#decision-points",
    "href": "planning-for-submission.html#decision-points",
    "title": "Planning for submission",
    "section": "Decision points ü§î",
    "text": "Decision points ü§î\nChoosing a platform to do your sequencing comes down to the question you are trying to answer. See the last row in the table above ‚ÄòBest use for‚Äô for some examples of why you might pick one platform over another!\nWhen you get in contact with a sequencing facility, the question they will ask you is not how many samples are you sequencing, but rather, how many reads do you need? This will determine what size flow cell you need, and to some extent, which platform you will use, as different platforms have different capacity (e.g,. Illumina NextSeq is a ‚Äòmedium throughput‚Äô platform, NovaSeq is a ‚Äòlarge throughput‚Äô platform). The number of reads you need scale with the size of the genome and/or complexity of your transcriptome.\nAs a general rule of thumb, for transcriptome sequencing you will need:\nTable 1: Reads per sample\n\n\n\nPurpose / Type\nApprox reads per sample\n\n\n\n\nGene expression profiling\n5‚Äì25 million\n\n\nComplete expression + alternative splicing\n30‚Äì60+ million\n\n\nDe novo transcriptome assembly\n~100+ million\n\n\n\n\n\nThe next thing the sequencing facility will ask you if you are doing short-read sequencing (Illumina) is do you want single-end or paired-end reads. This refers to whether you want a single read (read 1), sequenced from only one end of the library molecule (fragment), or if you want two reads per library molecule (read 1 and read 2, antisense and sense strands). Paired-end costs more, but gives you more resolution.\nThere are pros and cons to choosing either chemistry:\nTable 2: Single-end vs paired-end chemistry (short-read Illumina sequencing)\n\n\n\n\n\n\n\n\nChemistry\nPros\nCons\n\n\n\n\nSingle-end (SE)\nLower cost, fewer reads required (may be able to do more samples); sufficient for basic gene-level DGE\nLimited splice/isoform resolution; less confident mapping when mapping to a genome\n\n\nPaired-end (PE)\nBetter alignment; improved splice junction and isoform detection; more robust for complex transcriptomes or de novo transcriptome assembly\nHigher cost; ~2√ó sequencing required (two reads per fragment)\n\n\n\n\n\nLastly, if you are doing short-read sequencing (i.e., Illumina), the sequencing facility will ask you what read length you want. You can typically chose from between 50bp-300bp (platform-dependent). The choice between a lower or higher read length will be a balance of cost (higher read length = higher cost) and the level of information you need (complex, novel or de novo transcriptomes require higher read lengths; more straight forward analyses with well-annotated genomes can utilise lower read lengths). In contrast, for long-read sequencing platforms (ONT and PacBio), you do not specify a fixed read length. Instead, reads are generated as single, continuous sequences, and their length is determined by the size of the input molecules, the library preparation method, and the sequencing chemistry.\nChoosing a read length is a trade-off between cost, and the amount of information you will recover:\nTable 3: Read length (short-read Illumina sequencing)\n\n\n\n\n\n\n\n\nRead length\nPros\nCons\n\n\n\n\n50 bp\nLowest cost; highest sample multiplexing; sufficient for basic gene-level DGE in well-annotated genomes\nPoor isoform and splice junction resolution; higher multi-mapping\n\n\n100 bp\nGood balance of cost and information; reliable splice junction detection; widely used for standard RNA-seq\nSlightly lower throughput than 50 bp; may miss very complex isoforms\n\n\n150 bp\nImproved isoform resolution; better mapping across repetitive regions; useful for novel transcript discovery\nHigher cost; fewer reads per run\n\n\n300 bp\nMaximum per-read information; helpful for de novo transcriptome assembly\nRarely necessary for Illumina RNA-seq; expensive; reduced throughput\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE #1 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (15 mins)\n\n\n\nExample RNAseq scenario:\nYou are working on a mouse model of cancer genomics. You want to do differential gene expression analysis to compare tumour samples to non-cancerous control tissue, to see if you can find genes that are up or down regulated in the cancerous tissue. You have 40 RNA samples, and since your species has a high-quality reference genome and annotation (i.e., mouse: Mus musculus), you know you have a ‚Äúgood‚Äù genome assembly and annotations to map your sequencing data back to (more on ‚Äúgood‚Äù genomes later!). The mouse genome is ~2.7 Gb (= 2,700,000,000 bp), diploid, with ~20,000 protein-coding genes.\nYou are particularly interested in alternative splicing and novel splice junctions, as you suspect that cancer-associated genes are often regulated at the isoform level.\nYou will sequence your samples at the Otago Genomics Facility, and see on their website they have an Illumina MiSeq and an Illumina NextSeq 2000. Use this Illumina benchtop sequencing platforms comparison guide to help you decide.\n\n\n\n\n\n\nWhich platform will you chose?\n\n\n\n\n\nThe Illumina NextSeq 2000 is a ‚Äòmedium‚Äô sized short read sequencing platform, ideal for standard RNAseq, and is well-suited to this project. It can output up to 540Gb.\nThe Illumina MiSeq is a ‚Äòsmall‚Äô sized short read sequencing platform, better suited to QC or amplicon sequencing, and can output up to 30Gb. It is too small for this project.\n\n\n\nNext you need to decide how many reads you need.\nBased on table 1 above, how many reads do you need per sample?\n\n\n\n\n\n\nReads per sample choice:\n\n\n\n\n\nYou decide you need 30 million reads per sample. You pick the lower end of the scale, as you suspect the genes you are most interested in will be highly expressed, and don‚Äôt expect your tissue to have a particular high transcript diversity that would require more reads.\nYou work out what minimum output you need from the flow cell:\n30 mil reads * 40 samples = 1200 million reads (1.2B).\n\n\n\nNow you need to decide if you want paired-end or single-end reads.\nBased on table 2 above, what would you pick?\n\n\n\n\n\n\nPaired-end vs single end choice:\n\n\n\n\n\nPaired-end sequencing will give better detection of novel isoforms and splice junctions.\nThis doubles the number of reads generated per fragment and will give you better resolution.\n\n\n\nYou now need to decide which read length you need. Given the mouse genome is well-annotated, but you are looking for potentially novel isoforms, which read length would you pick, based on table 3?\n\n\n\n\n\n\nRead length choice:\n\n\n\n\n\n50 bp would be a good choice for a well-annotated genome like mouse for standard RNAseq, but does not suit this experiment, as you are looking for novel isoforms/alternative splicing.\n100bp is probably the best choice, balancing cost with novel isoform discovery.\nYou could also chose 150bp, if you want to be sure you‚Äôd capture novel isoforms, especially if they are quite long or complex genes - and don‚Äôt mind a higher cost.\n\n\n\nYou are now ready to pick your flow cell. Check out the Illumina NextSeq2000 flow cell specifications and chose which flow cell will suit this project best. There are four flow cells in ascending output size you can choose from: P1, P2, P3 and P4.\n\n\n\n\n\n\nWhich flow cell will you pick?\n\n\n\n\n\nChoices from earlier:\n\nTotal reads needed for your experiment: 1.2 billion reads.\n\nPaired end sequencing using 100bp read length (i.e., 2 x 100bp)\n\nCalculation: 1.2 billion reads x 100 (bp) x 2 (PE) = 240 Gb output is needed (i.e., 240 gigabase pairs, or 240 billion individual DNA bases sequenced).\nFlow cell options:\n\nP1 ‚Üí No 100bp option and way too low\n\nP2 ‚Üí 80 Gb (too low for 1.2B demand)\n\nP3 ‚Üí 240 Gb (fits 1.2B reads requirement exactly - best choice!)\n\nP4 ‚Üí 360 Gb (oversized for this project)\n\nNote: the maximum output stated for the flow cell is under optimal conditions, so the P3 flow cell choice just fits, but it is possible you will have less reads then anticipated (e.g., instead of 30 mil reads per sample, you may 28 mil per sample).\n\n\n\nCongratulations! You are now ready to sequence your RNAseq samples.\n\n\n¬†\nNow let‚Äôs look at DNA sequencing in more detail.\nDNA sequencing may refer to whole genome, whole exome, or targeted sequencing approaches.\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nmore explanation by someone who knows DNAseq better!\n\n\nFor Genome sequencing you will need:\n\n\n\n\n\n\n\n\n\nGenome size\nExample species\nApprox genome size\nApprox reads per sample\n\n\n\n\nTiny\nVirus\n&lt;0.1 Mb\n0.1‚Äì0.5 million\n\n\nSmall\nBacteria\n5 Mb\n5‚Äì10 million\n\n\nMedium\nYeast\n12 Mb\n10‚Äì20 million\n\n\nLarge\nFruit fly (D. melanogaster)\n175 Mb\n50‚Äì100 million\n\n\nVery Large\nHuman\n3 Gb\n600‚Äì1,200 million\n\n\nHuge\nWheat\n16 Gb\n6‚Äì12 billion\n\n\n\nWhere Mb = megabase pairs (i.e., 1 Mb = 1,000,000 bp)\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nCoverage. talking about average coverage - really repetitive regions can have very low covergae, other more easily resolved sections will have higher coverage.\nheterozygosity homozygosity.\nhaplotypes etc.\nStick mostly to decision points - not a huge lecture/tutorial on genome/ DNA biology. Assume learners haev a genetics background - they just have not yet translated that knowledge into a practical application of NGS.\n\n\n\n\n\n\n\n\n\n\nEXERCISE #2 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (10 mins)\n\n\n\nExample DNAseq scenario:\n\n\n\n\n\n\nFILL IN - THIS EXERCISE NOT COMPLETE\n\n\n\nProbably needs one or two more ‚Äòdecision point‚Äô exercises for learners.\n\n\nYou are want to de novo assemble the genome of the New Zealand swamp maire (Syzygium maire), a critically-endangered, endemic myrtaceae species, which is under threat from the pathogen myrtle rust.\nBased on genome sizes of related Syzygium and Myrtaceae species (e.g., Syzygium aromaticum ~370 Mb, S. grande ~405 Mb), you expect the S. maire genome to be on the order of ~350‚Äì400 Mb.\nDe novo genome assembly requires long read sequencing to resolve the longest contiguous sequences possible (ideally the full chromosome length, but that is often not easy or possible to achieve!).\n\n\n\n\n\n\nWhich long-read sequencing platform should you chose?\n\n\n\n\n\nThere are two long-read platforms ‚Äì PacBio and ONT. PacBio better for throughput (amount of reads you can get back) and for accuracy than ONT. FILL IN.\n\n\n\nThe S. maire genome was published in 2024 by Balkwill et al. 2024. Tree Genetics & Genomes. The authors also used Illumina sequencing in this paper. What did they use it for? Why do you think they chose to do Illumina sequencing for these samples rather than PacBio?\n\n\n\n\n\n\nSOLUTIONS (collapse this once complete):\n\n\n\n\n\n\n\n\n\nFILL IN - THIS EXERCISE NOT COMPLETE\n\n\n\n\n\n\nAnswer: 30 x samples at low coverage for resequencing.\nAnswer: cost, accuracy at SNP level. dont need to resolve full genomes as that was not their question.\n\n\n\n\n\n\n\nNote 1: Batch variation. Are you doing all your samples in one batch, or will you have multiple batches? Technical variation can occur, so you may want to wait and do all samples at once on one larger flow cell, or make sure you randomise samples across sequencing batches.\n\n\nNote 2: DNAseq vs RNAseq. You may have noticed we call it ‚ÄòRNAseq‚Äô, even though we convert the RNA into DNA before sequencing! By convention, this is still called RNAseq, to differentiate it from true DNAseq. ONT can directly sequence the RNA without converting it to DNA first; we call this native RNA sequencing.",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#nz-sequencing-facilities-and-services",
    "href": "planning-for-submission.html#nz-sequencing-facilities-and-services",
    "title": "Planning for submission",
    "section": "NZ sequencing facilities and services",
    "text": "NZ sequencing facilities and services\n\nCurrent as of: December 2025\n\n\n\n\n\n\n\nNOTE\n\n\n\nnot planning to go into detail at all on non-NGS services around NZ. Sticking to more higher throughput genomics.\n\n\nSequencing facilities which offer NGS services:\nOtago Genomics Facility (OGF)\nLocation: The University of Otago, Biochemistry Building.\n\nIllumina NextSeq 2000\n\nIllumina MiSeq\nONT P2 Solo\n\nONT MinION\nNanoString nCounter Analysis System (non-NGS)\n\nPerforms: Moderate to large scale RNAseq, DNAseq, amplicon seq etc\nMassey Genome Service (MGS)\nLocation: Massey University\n\n2 x Illumina MiSeq\n\nApplied Biosystems 3500xl capillary instrumentation (non-NGS).\n\nPerforms: small scale RNA or DNAseq, single gene (Sanger sequencing)\nAuckland Genomics\n\nplatforms: Illumina and ONT. They don‚Äôt list on their website which ones they have.\n\n\n\n\n\n\n\nFILL IN MORE DETAILS\n\n\n\nProcotocols available/ on offer- dont want to go into too much detail but becoems another decision point. Massey offer TruSeq lib prep. Auckland uses the newer kit. (slightly higher input required than the newer chemistry, both are very robust options. Newer one is supposed to be faster and better for more degarded RNA. Higher multiplexing for new kit 384 vs 96 for truseq).\n\n\nSee here for comparison between Illumina TruSeq stranded and Illumina stranded mRNA kits\nNon-service platforms around New Zealand:\nAgResearch\n- GenomNZ https://www.agresearch.co.nz/products-and-services/genomnz/ (Invermay) have a NovaSeq - they will do it if they have time and you ask nicely. They are a commercial animal DNA genotyping laboratory.\nLincoln\n- have MGI - compatible with Illumina libraries. not on website.\nother\nCustom science (supplier, does not do the sequencing for you)\n\nNew PacBio Revio in Auckland\n\n\nWorking with NZ sequencing facilities\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nstuff on submission process, show example form and brief explanation of how to fill out?\nhow do you get data back from them ? how do they transfer it?\nDo all the seq facilities in NZ give you data back demultiplexed by default?\nDo anyone use basespace to share reads with people?\n\n\n\n\nInternational sequencing services\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nInternational sequencing services - touch on this, why you may chose over NZ (or not chose!) then point towards the next section on ethical data management.",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "data-storage-and-management.html",
    "href": "data-storage-and-management.html",
    "title": "Genomic data storage and management",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#genomic-data-files",
    "href": "data-storage-and-management.html#genomic-data-files",
    "title": "Genomic data storage and management",
    "section": "Genomic data files",
    "text": "Genomic data files\nGenomic data files are huge, and for one project you will often have several hundred gigabytes (GB) to sometimes terabytes (TB) of data (more on the actual genomic file types in the next section Data wrangling and processing). You most likely won‚Äôt be able to store and analyse these on your local computer, or transfer the files in the ‚Äòtraditional‚Äô way using portable USB drives, so you‚Äôll need to make use of a high capacity storage (HCS), high performance computing (HPC), and file transfer protocols (FTP). An introduction to genomics is also an introduction to the world of high performance computing!\nCaveat: small genomes such as from bacteria often can be transferred, stored and analysed on your local computer.\nYou have a few options of how you want to store and analyse your data, which may be through HPC/HCS services offered by your University or Institute, or through the national computing and digital network REANNZ.",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#research-and-education-advanced-network-new-zealand-reannz",
    "href": "data-storage-and-management.html#research-and-education-advanced-network-new-zealand-reannz",
    "title": "Genomic data storage and management",
    "section": "Research and Education Advanced Network New Zealand (REANNZ)",
    "text": "Research and Education Advanced Network New Zealand (REANNZ)\nREANNZ is ‚Äú..a Crown-owned membership organisation that powers Aotearoa‚Äôs research and education network. Launched in 2007, their high-performance national digital network (or NREN) helps members collaborate and contribute to data-intensive and complex science and research initiatives ‚Äì both here in New Zealand and across the globe.‚Äù\nThey offer many products and services ‚Äì check out their website here ‚Äì but here we will focus on their HPC platform that you may chose to use to analyse your data.\nProjects on REANNZ\nTo use the HPC services, you first need to make or be listed as a member on a ‚ÄòProject‚Äô. A ‚ÄòProject‚Äô will have a code (e.g., nesi03181 or uoo00431) and will need to be linked to a funding source to charge back compute resources used. Multiple people can use one Project; this is often the preferable way to use a Project when collaborating on the same dataset or project. You‚Äôll need to discuss whether you need your own Project, or can be added to an existing Project, with whoever is supplying the funding (most likely your PI / supervisor).\nEither way, first make your own account using your institutional details by logging in here: https://my.nesi.org.nz/.\n\nFrom there, you can apply/access/view your Projects, and manage the compute resource allocation of the Project.\nOnce you have an account and a Project, you can start using the HPC by logging in to Open OnDemand here: ondemand.nesi.org.nz\n\nOnce logged in, you‚Äôll see an app-based dashboard.\nClick on ‚ÄòJupyter Lab‚Äô and then you can chose a few different settings before launching. For the most part, you will only need to change the Project Code and the number of hours you need the session open. You can leave the number of cores and memory per job as the default lowest settings.\n\nOnce the session is open, you can interact with your files through the directory structure on the left, and open either a Terminal or various other scripting programs through the Launcher. More on using the Terminal (also known as shell / unix shell / bash) in the next lesson.\nFor each Project, you will have a nobackup and a project directory. Keep your raw files in the project directory and do your analysis in the nobackup directory. As you can guess by the name, this directory is not backed up, and is best used for working analyses. Additionally, files not modified after 90 days are auto deleted. Final analysed files and imprortant scripts should be copied into the project directory once you have completed your analysis. You may be surprised by how many intermediate files you make and how much ‚Äòtinkering‚Äô you do during your analyses‚Äìmaking use of the two directories helps keep your file system tidier.\n\nNote: It can be a good idea to back-up raw genomic files on a HCS / reannz freezer? FILL\n\nGetting your genomic files on to the REANNZ cluster\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nHow do we actually get the genomic sequence files from the sequencing facility to the REANNZ cluster?\nGLOBUS\n\n\nWant more info?\n\nREANNZ provide extensive documentation on how to use their High Performance Computing (HPC) platforms.\n\n\nIn July 2025, the New Zealand eScience Infrastructure (NeSI) was integrated into REANNZ. You may have heard of NeSI before, but if not, it is good to be aware of the name, as you‚Äôll see some legacy branding in the REANNZ documentation or log-in platform (e.g., my.nesi.org.nz is still in use).",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#aoraki-at-the-university-of-otago",
    "href": "data-storage-and-management.html#aoraki-at-the-university-of-otago",
    "title": "Genomic data storage and management",
    "section": "Aoraki at the University of Otago",
    "text": "Aoraki at the University of Otago\nIf you are a University of Otago staff or student, you can use the ‚ÄúAoraki‚Äù HPC cluster. Like REANNZ, you will also connect to the cluster through an Open OnDemand app-based interactive web page.\nhttps://rtis.cspages.otago.ac.nz/research-computing/cluster/index.html",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#other-universities-hpchcs-options",
    "href": "data-storage-and-management.html#other-universities-hpchcs-options",
    "title": "Genomic data storage and management",
    "section": "Other universities HPC/HCS options?",
    "text": "Other universities HPC/HCS options?\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nAuckland? wellingotn? massey? UC? probably cant cover all but need to list some of these.",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#ethical-data-management",
    "href": "data-storage-and-management.html#ethical-data-management",
    "title": "Genomic data storage and management",
    "section": "Ethical data management",
    "text": "Ethical data management\n\nFAIR and CARE\nIn 2016, the FAIR principles were published in Scientific Data. These guidelines set to provide a standard through which to improve digital assets:\n\nFindability\n\nAccessibility\n\nInteroperability\n\nReuse\n\nPart of conducting FAIR research is having a reproducible research pipeline. One way this can be done is by documenting your work on a version control system like GitHub. See our GA workshop for more on Reproducibility with Git and Quarto.\nOpen science advocates have embraced this FAIR framework, while others critise its lack of protection of data, for not considering the rights and interest of those that should hold governance over data, in particular, indigenous peoples. In response to this, the CARE framework has also been proposed by Global Indigenous Data Analysis, to complement the existing FAIR principles:\n\nCollective benefit\n\nAuthority to control\n\nResponsibility\n\nEthics\n\n\nThis story ‚ÄúOpen with care; Indigenous researchers and communities are reshaping how Western science thinks about data ownership‚Äù is an interesting read on these perspectives.\nThe Aotearoa Genomic Data Repository (AGDR) and Rakeiora platform are examples of services that have adopted these CARE principles.\n\n\nAotearoa Genomic Data Repository (AGDR)\nFrom the AGDR website:\n‚ÄúThe Aotearoa Genomic Data Repository provides secure within-nation storage, management and sharing of non-human genomic data generated from biological and environmental samples originating in Aotearoa New Zealand. This resource has been developed to follow the principles of MƒÅori Data Sovereignty, and to enable kaitiakitanga (guardianship), so that iwi, hap≈´ and whƒÅnau (tribes, kinship groups and families) can effectively exercise their responsibilities as guardians over biological entities that are taonga (precious or treasured). While the repository is designed to facilitate the sharing of data ‚Äî making it findable by researchers and interoperable with data held in other genomic repositories ‚Äî the decision-making process regarding who can access the data is entirely in the hands of those holding kaitiakitanga over each data set.‚Äù‚Äù\nThe AGDR is enabled by MBIE funding to Genomics Aotearoa.\n\n\nRakeiora Genomics platform\nThe Rakeiora Genomics Platform is designed to enable and test pilot precision medicine research, linking genomics and health.\nThey have chosen a walled garden approach to this infrastructure.\n‚ÄúThis means that all genomic data and health data, and its analysis, are undertaken only within this computational environment ‚Äì the data never leave and are certainly never downloaded to a researcher‚Äôs own computer or a hospital clinical laboratory computer‚Ä¶\n‚Ä¶Its modular nature will allow linkage (with consent) to other health data systems currently under development in Aotearoa New Zealand. This approach in particular addresses transparency of use and control over narratives. Lack of these features in other precision medicine platforms worldwide has led to significant problems for patients and research participants, including indigenous communities; learning from these negative experiences is key to avoid repeating them.‚Äù ‚Äì From the Genomics Aotearoa website.",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#public-data",
    "href": "data-storage-and-management.html#public-data",
    "title": "Genomic data storage and management",
    "section": "Public data",
    "text": "Public data\nYou are probably familiar with using the NIH NCBI database, hosted by the United States Government, for things such as BLAST searches and literature searches.\nNCBI has a repository called the Sequence Read Archive (SRA), which is where a large proportion of genomic data from all over the world is stored, as publicly available raw, high-throughput, sequencing data.\nIf your data has no ethical concerns, this can be a great resource for making your data freely available and easily citeable in publications.\nHere we will not go into detail on how to either download or upload data to the SRA (see documentation on their website). But some points to be aware of are:\n\nA BioProject is a way to link all the sequencing and biological data together under one umbrella (as a general rule, 1 publication = 1 BioProject, but many groups use a single BioProject for multiple publications). If you are uploading your own data, we recommend starting with creating a BioProject, which will then give you a single accession (e.g., PRJNA31257) to use for the next steps (BioSample + SRA raw read uploads).\nA BioSample is a unique descriptor of the biological source material (e.g, all the biological metadata of your sample ‚Äì species, sex, age, location, tissue, etc.). This is often (but not strictly) set up as 1 BioSample = 1 library. Each BioSample accession will be linked to the matching sequence data in the SRA, and all housed under one BioProject accession number.\n\nEqually, if you are downloading data from the SRA, you can make use of BioProject and BioSample accessions to identify and orientate yourself to the data.\nExample BioProject:\n\n\n\n\n\n\nHuman airway smooth muscle transcriptome study\n\n\n\n\n\nYou can see there are 16 SRA experiments and 16 BioSamples ‚Äì you can guess that these probably match one to one.\nThere are also GEO datasets (Gene Expression Omnibus) associated with this study, which are repositories for functional genomic data. These are a more processed form of the data e.g., count tables and differential expression data.\n\n\n\n\n\nThis is not the only public repository of sequence reads, some other examples include: European Nucleotide Archive (ENA) and the DNA data bank of Japan DDBJ Sequence Read Archive (DRA). These data banks are linked together via the International Nucleotide Sequence Database Collaboration. NCBI also details some of the collaborative projects here (e.g., The Taxonomy Project, The Feature Table).",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#discussion",
    "href": "data-storage-and-management.html#discussion",
    "title": "Genomic data storage and management",
    "section": "DISCUSSION üí¨",
    "text": "DISCUSSION üí¨\n\nWhat ethical considerations do you need to take into account when storing and sharing your data for your own personal project?\n\n\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nOther discussion points?",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "organisation-tidiness.html",
    "href": "organisation-tidiness.html",
    "title": "Organisation and tidy data",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Organisation and tidy data"
    ]
  },
  {
    "objectID": "organisation-tidiness.html#metadata",
    "href": "organisation-tidiness.html#metadata",
    "title": "Organisation and tidy data",
    "section": "Metadata",
    "text": "Metadata\nWhen we think about the data for a sequencing project, we often start by thinking about the sequencing data that we get back from the sequencing centre. However, equally or more important is the data you‚Äôve generated about the sequences before it ever goes to the sequencing centre. This is the data about the data, often called the metadata. Without the information about what you sequenced, the sequence data itself is useless.\n\n\n\n\n\n\nEXERCISE üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (3 mins)\n\n\n\nWhat kind of data and information have you generated (or think you will generate) about your samples that can be considered metadata? How do you store this information?\nDiscuss with the group. When you are ready, click on ‚ÄòSolutions‚Äô for a few examples of what these metadata could be.\n\n\n\n\n\n\nSOLUTIONS\n\n\n\n\n\n\nExperimental conditions describing the biological samples, such as: temperature, weight, length, treatment.\nLaboratory/technical data, such as: protocol or kit used to extract DNA/RNA, specific processing equipment, concentrations or quality indicators (e.g., Nanodrop, Qubit, or Bioanalyzer results)\n\nLab notebook notes about how you conducted those experiments.\n\nSpreadsheet or tabular data with the data from your experiment and whatever you were measuring for your study.",
    "crumbs": [
      "Organisation and tidy data"
    ]
  },
  {
    "objectID": "organisation-tidiness.html#structuring-data-in-spreadsheets",
    "href": "organisation-tidiness.html#structuring-data-in-spreadsheets",
    "title": "Organisation and tidy data",
    "section": "Structuring data in spreadsheets",
    "text": "Structuring data in spreadsheets\nRegardless of the type of data you‚Äôre collecting, there are standard ways to enter that data into the spreadsheet to make it easier to analyse later. We often enter data in a way that makes it easy for us as humans to read and work with it, because we‚Äôre human! Computers need data structured in a way that they can use it. So to use this data in a computational workflow, we need to think like computers when we use spreadsheets.\nThe cardinal rules of using spreadsheet programs for data:\n\nLeave the raw data raw - do not change it!\n\nPut each observation or sample in its own row.\n\nPut all your variables in columns - the thing that vary between samples, like ‚Äòstrain‚Äô or ‚ÄòDNA-concentration‚Äô.\n\nHave column names be explanatory, but without spaces. Use ‚Äò-‚Äô, ‚Äô_‚Äô or camel case instead of a space. For instance ‚Äòlibrary-prep-method‚Äô or ‚ÄòLibraryPrep‚Äôis better than ‚Äôlibrary preparation method‚Äô or ‚Äòprep‚Äô, because computers interpret spaces in particular ways.\n\nDo not combine multiple pieces of information in one cell. Sometimes it just seems like one thing, but think if that‚Äôs the only way you‚Äôll want to be able to use or sort that data. For example, instead of having a column with species and strain name (e.g.¬†E. coli K12) you would have one column with the species name (E. coli) and another with the strain name (K12). Depending on the type of analysis you want to do, you may even separate the genus and species names into distinct columns.\n\nExport the cleaned data to a text-based format like CSV (comma-separated values) format. This ensures that anyone can use the data, and is required by most data repositories.\n\n\n\n\n\n\n\nEXERCISE üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (2 mins)\n\n\n\nBelow is some potential spreadsheet data generated about a sequencing experiment.\n\nDiscuss some of the problems with the spreadsheet data shown above. You can look at the image, or download the file to your computer via this link and open it in Excel.\nWhen you are ready, click on ‚ÄòSolutions‚Äô to see a clean version of the data.\n\n\n\n\n\n\nSOLUTIONS\n\n\n\n\n\nHere is a clean version of the data (download link here). Note the following changes to make the data tidy:\n\nSections reordered to be in single columns\n\nRemoved formatting/colours which won‚Äôt be interpreted by most computational tools\n\nHeader information about the reference, facility, read length etc moved to their own columns\n\nSpaces replaced in column names with _\nStandarised language for mutator and cit columns i.e., \"+\" became plus\n\nData has also been saved as a tsv file rather than excel format.\n\n\n\n\n\n\n\n\nTidy data principles\nThe simplest principle of Tidy data is that we have one row in our spreadsheet for each observation or sample, and one column for every variable that we measure or report on. As simple as this sounds, it‚Äôs very easily violated. Most data scientists agree that significant amounts of their time is spent tidying data for analysis.\nThe R package Tidyverse was specifically developed to deal with data cleaning and manipulation for analysis. Sidenote: a Genomics Aotearoa workshop on data manipulation with tidyverse tools is in development!\n\n\n\n\n\n\nEXERCISE üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (1 min)\n\n\n\nHave a look at these column names and the differences between the good names and names to avoid:\n\nWhat do you notice? Jot down your thoughts before looking at the ‚ÄòSolutions‚Äô below:\n\n\n\n\n\n\nSOLUTIONS\n\n\n\n\n\n\nGood column names avoid using spaces and any special characters beyond underscores (_)\nCamel case is often a good alternative naming convention\n\nNote hyphens (-) are also avoided as they can cause headaches with R.\n\nR also does not like column names that begin with a number (e.g., Observation_01 is fine, 01_Observation is not)\n\n\n\n\n\n\nThere are lots of different conventions people use to represent missing values. You should especially avoid representing a missing value as a 0 (zero), as zero implies that a measurement was taken and the result was zero.\nThe best option is to leave missing values as blank or designate them as an NA in your spreadsheet.\nSee below a few common values used for indicating a missing value:",
    "crumbs": [
      "Organisation and tidy data"
    ]
  },
  {
    "objectID": "outtakes-notes.html",
    "href": "outtakes-notes.html",
    "title": "Outtakes and notes",
    "section": "",
    "text": "WORK IN PROGRESS\n\n\n\n\n\n\nOuttakes and notes\nadd a prerequisates section to the home page. this is a ‚Äòfoundational‚Äô level workshop. As with all GA workshops, learners are expected to have a basic (undergraduate) level understanding of biological and genetic concepts.\nNon-NGS sequencing around New Zealand:\nLincoln\n- DNA sequencing service (Sanger)\nOtago - Genetic Analysis Service (GAS) (Sanger)\ngo back over genmic data carpentry from the carpentries to see what else they go over.\nAssembly QC: biological and technical assessments of the three Cs (contiguity, correctness, completeness). from : https://genomicsaotearoa.github.io/BioinformaticsTrainingProgramme/portfolio.html#long-read-genome-assembly\nwhy would you chose internantional seq options over nz, cost, local.\nintro to bioinformatics.",
    "crumbs": [
      "_outtakes/notes"
    ]
  },
  {
    "objectID": "test-styling.html",
    "href": "test-styling.html",
    "title": "test styling",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "_test styles"
    ]
  },
  {
    "objectID": "test-styling.html#header-2",
    "href": "test-styling.html#header-2",
    "title": "test styling",
    "section": "Header 2",
    "text": "Header 2\ntext\n\nHeader 3\ntext\n\nHeader 4\ntext\n\nHeader 5\ntext",
    "crumbs": [
      "_test styles"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#getting-started-with-genomics",
    "href": "index.html#getting-started-with-genomics",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "Getting started with genomics",
    "text": "Getting started with genomics\nThis is a beginner-friendly workshop, designed to get you started with the world of genomics. Whatever you‚Äôre doing‚Äîwhether it‚Äôs transcriptomics, genome assembly, variant calling, metagenomics, or something else‚Äîif you will be using genomic data this workshop is for you!",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#whats-covered-in-this-workshop",
    "href": "index.html#whats-covered-in-this-workshop",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "What‚Äôs covered in this workshop",
    "text": "What‚Äôs covered in this workshop\n\nOrganisation‚Äîfrom messy lab books and excel spreadsheets to tidy, computer-friendly data\n\nWorking with sequencing facilities and understanding genomic data types\n\nData storage repositories, public services and facilities, and principles of FAIR and CARE\nQuality control, wrangling of raw reads and an introduction to genomic terminology",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#whats-not-covered-in-this-workshop",
    "href": "index.html#whats-not-covered-in-this-workshop",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "What‚Äôs NOT covered in this workshop",
    "text": "What‚Äôs NOT covered in this workshop\n\nBasic descriptions of biological and genetic concepts (i.e., we assume the learner is already familiar with DNA/RNA, PCR, transcription etc. to an undergraduate level).\n\nNon-NGS sequencing and services (e.g., Sanger sequencing, qPCR, genotyping, probe-based applications such as microarrays and NanoString nCounter).\n\nGenomic analysis workflows (beyond the basics of initial quality checks of raw reads)\nThe basics of cluster or HPC resourcing and specialised software (e.g., we do not cover schedulers such as SLURM, partitions/CPUs/GPUs, chosing compute allocation allowance). See our workshop on Introduction to Bash Scripting and HPC Job Scheduler for this.\nUsing shell or other bioinformatic tools, beyond the very basics (e.g., we do not cover writing/submitting bash scripts, modules, accessing the cluster using ssh).",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#glossary",
    "href": "index.html#glossary",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "Glossary",
    "text": "Glossary\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nAdapter\nShort synthetic DNA sequence ligated to the DNA molecule during library prep which allows the molecule to bind to the flow cell during sequencing and also provides a primer binding site\n\n\nbp\nBase pair\n\n\nHCS\nHigh Capacity Storage\n\n\nHPC\nHigh Performance Computing\n\n\nIndex\nAlso known as a barcode. Short unique sequence added to each DNA molecule in one library, allowing the identification of that library/sample and thereby enabling pooling of the libraries (one run = cheaper).\n\n\nMb\nMegabase pair (1,000,000 bp)\n\n\nMB\nMegabyte\n\n\nMultiplexing\nSequencing multiple samples simultaneously in one run by combining libraries into one pool. Samples (i.e., libraries) are de-multiplexed (separated) in silico usually by the technician, based on unique indices.\n\n\nGb\nGigabase pair (1,000,000,000 bp)\n\n\nGB\nGigabyte\n\n\nNGS\nNext-generation sequencing\n\n\nSE / PE\nSingle-end / Paired-end",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#attribution",
    "href": "index.html#attribution",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "Attribution",
    "text": "Attribution\nParts of this workshop were adapted from and inspired by content from The Carpentries Data Carpentry lessons on Genomics.\n\n\n\n\n\n\nCopyright information:\n\n\n\n\n\nAll Carpentries instructional material is made available under the Creative Commons Attribution license CC BY 4.0. The material in this workshop is not endorsed by the Carpentries and has been adapted by Genomics Aotearoa for our own teaching purposes.\nIn this workshop, the following lessons were adapted from The Carpentries Data Carpentry in the manner stated below:\n\nOrganisation and tidy data section has re-used material from Project Organization and Management for Genomics.\nData Wrangling and Processing for Genomics. Currently not using this workshop but likely to re-use.\n\n\n\n\nMaterial is used in this workshop from our other Genomics Aotearoa workshops, as below:\n\nMaterial from our Introduction to Shell workshop is re-used in the Genomic data wrangling and processing section.\n\nMaterial from our Introduction to R workshop - section on working with spreadsheets is re-used in Organisation and tidy data.\n\nOther material used in this workshop:\n\nIllumina library prep molecular workflow diagram in Planning for submission from Illumina Stranded mRNA Prep, Ligation Data Sheet. M-GL-02143 v1.0\n\nBioanalyzer trace of final mRNA library in Planning for submission from Illumina Stranded mRNA Prep, Ligation Protocol Document # 1000000124518 v04.\n\nPacBio SMRTbell adapters image in Planning for submission from Template Preparation and Sequencing Guide P/N 000-710-821-13.\n\nAdapter dimer image from Illumina general knowledge base used in Planning for submission.\n\nDefinitions:\n\nRe-used material: Almost word-for-word, including images, with minor wording or styling modifications.\n\nMinimally-adapted material: Inspired by stylistic choices and general workflow, but material is primarily developed by Genomics Aotearoa.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "",
    "text": "Made with ‚ù§Ô∏è and Quarto",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html",
    "href": "data-wrangling-and-processing.html",
    "title": "Genomic data wrangling and processing",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#command-line-interface-cli-vs-graphical-user-interface-gui",
    "href": "data-wrangling-and-processing.html#command-line-interface-cli-vs-graphical-user-interface-gui",
    "title": "Genomic data wrangling and processing",
    "section": "Command-line interface (CLI) vs graphical user interface (GUI)",
    "text": "Command-line interface (CLI) vs graphical user interface (GUI)\nCommand line interface (CLI) and graphic user interface (GUI) are different ways of interacting with a computer‚Äôs operating system. They have different pros and cons. Most people are familiar with the GUI (i.e., point and click) as it is the default interface for most software, particularly on Windows and Mac OS. When using the GUI, you see and interact with visual representations of files, folders, applications, and most other functions of your computer. When using the CLI, you work largely with text representations of software, files, folders, input and output. The shell is a program that allows you to control your computer by typing instructions on the CLI with a keyboard.\nThere are several reasons to learn how to use the CLI:\n\nFor most bioinformatics tools, there are no graphical interfaces. If you want to work in metagenomics or genomics, you‚Äôre going to need to use the CLI/ shell.\n\nThe shell gives you power and allows you to work more efficiently. Tasks that are repetitive (e.g.¬†renaming hundreds of files) can be automated. Tasks that are tedious (e.g.¬†testing a range of input parameters) can be simplified.\n\nTo use remote computers or cloud computing, you often need to use the shell.\n\nHere we will show you a quick introduction to using the shell to quality check your raw reads. For more on the shell, see our workshops on Introduction to Shell and Intermediate Shell.\n\nNote: you‚Äôll hear the terms ‚Äòshell‚Äô, ‚Äòbash‚Äô, ‚Äòunix‚Äô, ‚Äòterminal‚Äô and ‚Äòcommand-line‚Äô used almost interchangeably. For beginners, you can think of them as essentially all the same thing! As you gain more computational skills, you can dig into the differences.",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#first-check-that-the-data-are-not-corrupt",
    "href": "data-wrangling-and-processing.html#first-check-that-the-data-are-not-corrupt",
    "title": "Genomic data wrangling and processing",
    "section": "First, check that the data are not corrupt",
    "text": "First, check that the data are not corrupt\nBelieve it or not, computers can make mistakes! When your data files are being copied over from the sequencing facility to cloud storage, errors can occur that cause your files to become corrupted. This is not always obvious based on file size or a quick look at the contents. The first thing you‚Äôll want to do is run a checksum, which will output a fixed-length message of 16 bytes‚Äì a unique identifier of each file. The files should also come with the checksums run by the technician at the sequencing facility. Check out the section on Data Integrity in our GA shell workshop for more information on how to run this.",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#understanding-genomic-file-types",
    "href": "data-wrangling-and-processing.html#understanding-genomic-file-types",
    "title": "Genomic data wrangling and processing",
    "section": "Understanding genomic file types",
    "text": "Understanding genomic file types\nThe files you will get back from the sequencing facility will most likely end in .fastq.gz\nThe .gz indicates it is a compressed gzip file. For most genomic analyses, you do not need to unzip these first‚Äìthis saves you storage space, as unzipped files can be double or triple the zipped size!\nThe fastq indicates the file is in FASTQ format. FASTQ files are a text-based format that stores the raw read sequences, along with a quality score for each base.\nThe first 4 lines of a fastq file describe one sequence read:\n\nThe first line is the header information, beginning always with an @. This is the instrument-specific, run identifier and read identifiying information.\n\nV350304715 = instrument-specific\n\nL3 = lane 3 on the flow cell. Can be used for troubleshooting if something globally went wrong with sequencing.\n\nC001 = cluster identifier (can be used for troubleshooting, same as above).\n\nR001 = Read 1. All the reads in this file are read 1. If you have paired-end data, you‚Äôll have a corresponding read 2 file.\n\n00020454 = unique identifier for that read.\n/1 = indicates this is a pair member. Only paired-end data have the /1 or /2 additional identifier.\n\nEach instrument and chemistry will have slightly different header information. The main thing to look out for are indications of the data being read 1 or read 2 (indicates antisense or sense strand data, for protocols that can differentiate strandedness) and whether it is part of a mate pair (indicated by the /1 or /2)\nThe second line is the actual sequence. Count the number of bases ‚Äìwhich read length was chosen for this dataset?\nThe third line is just a ‚Äú+‚Äù. This can be optionally followed by the same sequence identifier (and any description) again.\nThe fourth line is the quality score. Each base in line 2 has a corresponding quality score, indicated by an ASCII character in line 4.\nFrom left to right, these are the quality scores in increasing order of quality:\n!\"#$%&'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\nSo, if a single base has a quality score of !, which corresponds to a Q-score of 0, this indicates exceptionally poor quality. The sequencing machine was not able to resolve which base it should be. Often these will be shown as N‚Äôs.\nConversely, if a single base has a quality score of I, which corresponds to a Q-score of 40, this indicates very high quality. The sequencing machine was ‚Äúvery confident‚Äù that the base called is correct (Q40 indicates an error probabilty of 0.0001, i.e., a 1 in 10,000 chance of the base being called wrong, on average. I is near the upper end of typically achieved quality values, but higher is possible.\nFor more on quality scores, you can also read this Illumina guide here. Note there are different types of encoding, but you will most frequently encounter Phred+33.\nWe can assess the quality score across all reads using software called FastQC, and trim down reads to remove poorer quality bases below a set threshold (generally with newer sequence data, you can use Q30 or Q40 as a cut-off). We won‚Äôt cover trimming here, see our workshop on RNA-seq Data Analysis for a step-by-step guide.\n\nOther genomic file types\nWe‚Äôve talked about fastq and gz files types, but there are some other common genomic file types you should know about.\nYou should also be aware that the extension on the file type is largely there just so you as a human know what kind of file it is. When using the CLI, the computer does not care what the extension says.\n\n\n\nExtension\nName\nDescription\n\n\n\n\n.fasta or .fa, .fna, .faa\nFASTA, FASTA nucleic acid, FASTA amino acid\nContains sequence data. Each sequence starts with a single header line starting with a &gt;, followed by the nucleotide (or amino acid in case of .faa) sequence on the second line. No quality encoding included.\n\n\n.bam .sam\nBinary/Sequence Alignment Map\nContains alignment information of your reads/sequences that are mapped against a reference sequence (e.g., genome). BAM are the compressed, computer-readable only version; SAM are human-readable but larger files. Somewhat interchangeable file types.\n\n\n.vcf\nVariant Call Format\nContains sequence variants called relative to a reference genome. Split into two sections; the header information and the records. See our Intro R workshop, section on VCF files.\n\n\n.gtf\nGeneral Feature Format\nContains genome annotation data.\n\n\n\n\n\nReal examples:\n\n\n\n\n\n\nFASTA\n\n\n\n\n\nFASTA file containing cds data from a genome, opened in a text editor: \n\n\n\n\n\n\n\n\n\nBAM/SAM\n\n\n\n\n\nadd screenshots!\n\n\n\n\n\n\n\n\n\nVCF\n\n\n\n\n\nVCF file opened in excel: \n\n\n\n\n\n\n\n\n\nGTF\n\n\n\n\n\nGTF file opened in a text editor:",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#fastqc---quality-scoring-of-raw-reads",
    "href": "data-wrangling-and-processing.html#fastqc---quality-scoring-of-raw-reads",
    "title": "Genomic data wrangling and processing",
    "section": "FASTQC - quality scoring of raw reads",
    "text": "FASTQC - quality scoring of raw reads\nAll fastq files, regardless of which kind of sequencing was performed, should be interrogated using a program called FastQC. Most HPC services (e.g., REANNZ) come with this program (and many other commonly used programs) pre-installed, so you likely will not need to install it anywhere.\nFastQC will give you a good overview of the quality of the reads (i.e., how confidently each base was called by the sequencing platform) and a few other statistics about the reads. Each statistic will be assigned a PASS, WARNING or FAIL:\n PASS ¬†¬†¬†  WARNING ¬†¬†¬†  FAIL\nThe following examples come from the ‚ÄòGood Illumina Data‚Äô and ‚ÄòBad Illumina Data‚Äô reports from the Babraham Bioinformatics website.\n\nEXAMPLES: Good vs bad sequence data\nBelow are the summarised pass, warning, fail statistics for the good (left) and bad (right) data. \nHere we will choose a few of these as examples to delve into:\n\nPer base sequence quality\nThe per base sequence quality is the first plot you can use to assess the quality. You can picture the reads as being all stacked on top of each other, and the average quality at each position (x-axis) shown as a boxplot (i.e., position 1 shows a boxplot of the quality scores of base pair #1 in all reads, position 2 shows a boxplot for base pair #2, and so on).\nThe quality score is shown on the y-axis. A score of below Q20 (error probabilty = 0.01, or 1 in 100 bases are incorrect on average) is shown as red - boxplots that extend in to this section indicate positions in the read that are poor quality.\nIn general, when you are trimming your reads you should pick a quality cut off of at least Q30 (error probabilty = 0.001; 1 in 1000), and some researchers even use Q40 (error probabilty = 0.0001; 1 in 10,000) for newer data. If you are working with older data (10+ years old, sequenced before ~2014), you may need to pick Q20 as a cut-off. These plots help you decide what is best for your data.\nAfter trimming reads, you should run FastQC again to compare how the average quality has changed and see how many reads are retained after trimming.\nGood data: Per base sequence quality \nIn this ‚ÄòBad data‚Äô below, we can see most reads are dropping in to the Q20 and below range from about base position 24 onwards to position 40. This is a typical pattern, where sequence quality tends to drop off around the 3‚Äô end for Illumina reads.\nBad data: Per base sequence quality \n\n\nPer sequence quality scores\nThe per sequence quality scores plots the Q-score per sequence, rather than per base position as above. The average Q-score for the whole read is taken, then plotted to show how many reads have that average score. Below we can see that for the good data and bad data, almost all reads sit above Q30.\nGood data: Per sequence quality scores \nFor the bad data, we can see that the larger peak of reads sits at a slightly lower (and wider) Q score, and there is a second peak at a very poor score of around Q17. These data show us that there may be a large proportion of reads with a high Q-score retained after trimming (good news!). The data has been given a ‚Äòpass‚Äô by FastQC, indicating it has not dropped below the threshold for this category to be given a warning or fail.\nBad data: Per sequence quality scores \n\n\nOverrepresented sequences\nMultiple sources can cause overrepresented sequences in your dataset. It can be a true biological or experimental effect, for example if you expect a few genes to be exceptionally highly expressed or if you have done targeted amplicon sequencing. However, it often reflects an issue that may have happened during extraction or library prep. Contaminating rRNA is a common culprit in RNAseq, as rRNA exists at a much higher concentration than other mRNAs in the cell. You may have to make a judgement call whether your data is still useable if it is highly contaminated. While contaminating reads can be filtered out, you‚Äôll have less useable reads. PCR overamplification during the library prep can also be an issue - in which case it may be possible to repeat part of the library prep with less PCR cycles.\nFor our good data, no overrepresented sequences were detected:\n\nHere is a snippet of our bad data, showing a ‚Äòwarning‚Äô with multiple overrepresented sequences detected, and the count and percentage of the total reads is also shown:\n\nFastQC looks for hits that are matches in a database of common contaminants. No hit was detected for any of these sequences, but it is worth BLASTing some of the highest count sequences to find the culprit.\n\n\n\n\n\n\nEXERCISE üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (1 min)\n\n\n\nWhat percentage of reads would need to be overrepresented for this category to be given a fail?\nUse the FastQC help guide here.\n\n\n\n\n\n\nSOLUTION\n\n\n\n\n\nIf any sequence is found to represent more than 1% of the total it will get a fail.",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#good-genome-bad-genome",
    "href": "data-wrangling-and-processing.html#good-genome-bad-genome",
    "title": "Genomic data wrangling and processing",
    "section": "Good genome, bad genome?",
    "text": "Good genome, bad genome?\nYou will often hear geneticists refer (somewhat colloquially) to ‚Äúgood‚Äù and ‚Äúbad‚Äù genome assemblies. But what does this actually mean? And how can you tell whether a species you are working on has a good genome assembly?\nIn practice, we assess genome assemblies using a few metrics that capture contiguity and completeness.\nCommon genome assembly metrics\n\nContiguity is often measured as contig and scaffold N50, which is the length cutoff for the longest contigs that contain 50% of the total genome length. In this era of long-read genome assemblies, a contig N50 over 1 Mb is generally considered good. Excerpt taken from PacBio article.\nAlso see Wiki entry on N50/L50.\nCompleteness is often measured using a BUSCO (Benchmarking Universal Single-Copy Orthologs) score, which measures completeness using sets of conserved, single-copy genes expected to be present in most species within a specified lineage.\n\nReported as percentages of complete, duplicated, fragmented, and missing genes. &lt;- change to example.\nGenome assemblies can be described more qualitatively as (in order of less to more complete):\n\nContig-level ‚Äì sequences are assembled but not ordered or oriented. Often can be thousands to hundreds of thousands of contigs.\n\nScaffold-level ‚Äì contigs linked together, often with gaps. None are placed (i.e., chromosome known) or localised (i.e., orientation on chromosome known).\n\nChromosome-level ‚Äì one or more chromosomes complete, but some unplaced scaffolds may be present.\n\nComplete genome - all chromosomes are resolved with no gaps. Not necessarily telomere-to-telomere (T2T).\n\nSee NCBI Glossary for Assembly level.\n\n\nWhat do we mean by a ‚Äúgood‚Äù genome?\nA good genome assembly is typically one that is:\n\nHighly contiguous\nReads have been assembled into long sequences called contigs, ideally approaching full chromosome lengths.\nBiologically complete\nMost expected genes are present (high BUSCO completeness).\nStructurally accurate\nLarge-scale errors such as mis-joins or collapsed repeats are minimised.\n\n\n\nAssembly quality vs annotation quality\nIt is important to distinguish between:\nGenome assembly i.e., the reconstructed DNA sequence itself, and the Genome annotation, which is the identification and labelling of genomic features, including gene structures (exons, introns, and CDS), non-coding RNAs (e.g., rRNA, tRNA and lncRNA), and associated identifiers such as gene_id, transcript_id, and database cross-references.\nA genome can be well assembled but poorly annotated, or vice versa.\n\nEXERCISES üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (6 mins):\nHow would you describe these genomes?\nLook at the assembly stats and make some notes of how ‚Äògood‚Äô you think each assembly is.\n\n\n\n\n\n\nEXERCISE #1 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (3 mins) - Human Genome Assembly\n\n\n\nHuman Genome assembly GRCh38.p14\n Note: RefSeq is the curated database. GenBank is the non-curated, anyone-can-submit-to database.\n\nJot down your thoughts before looking at the solution below:\n\n\n\n\n\n\nHuman genome solution\n\n\n\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nChromosome level - very high quality. busco score - very close to complete. very good genome\nnumber of extra scaffolds and contigs is very low (470 s / 996 c - it can be thousands of extra so hundreds is pretty good!)\nscaffold and contig N50. describe these!\n\n\ncollapse solution when complete\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE #2 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (3 mins) - Sea Anemone Genome Assembly\n\n\n\nNematostella vectensis (sea anemone) Genome assembly ASM20922v1\n\n\nJot down your thoughts before looking at the solution below:\n\n\n\n\n\n\nSea anemone solution\n\n\n\n\n\n\n\n\n\nFILL IN HERE\n\n\n\nscaffold level - medium quality. but the N50 is below 1mb, at 472.6kb scaffold. not great! quite fragmented.\nbusco score pretty good despite lack of placed scaffolds. contig/scaffold N50 - high enough that most genes are resolved.\nassembly itself not amazing, but annotation is probably good enough for gene level compariosn with other species.\nLarger scale structural variants and synteny difficult or erroneous to resolve. -&gt; is this true?\n\n\ncollapse=‚Äútrue‚Äù\n\n\n\n\n\n\nExtra for experts\n\n\n\nHere is the original paper for the curious: Putnam et al.¬†2007.\nThe authors claim the genome reveals ‚Äúancestral eumetazoan genomic organization‚Äù. How did they assess this and what conclusion did they make about the eumetazoan ancestor resemblance to modern vertebrates, sea anemones and protosomes? Do you think they had a ‚Äògood‚Äô enough genome to assess this?\n\n\n\n\n\n\nExtra for experts solution\n\n\n\nNEED TO FACT CHECK THIS, COLLAPSE WHEN COMPLETE\nThe authors used synteny analysis. They found many major genes, such as Hox genes, retained the same intron/exon structure in sea anemones as vertebrates, but this was not retained in model protosome species. Based on this they conlcuded that sea anemone genomes more closely resemble vertebrates than protosome species (fly, nematode, annelid) do. While the genome assembly itself is quite fragmented, the annotations are quite good, indicating that any conclusions the authors made comparing genomes and a gene stucture level are likely quite robust, but it would not be feasible with this assembly to make any conclusions based on larger genomic structure (i.e., at closer to chromosome level).",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  }
]