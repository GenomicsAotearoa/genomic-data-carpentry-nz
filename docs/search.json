[
  {
    "objectID": "planning-for-submission.html",
    "href": "planning-for-submission.html",
    "title": "Planning for submission",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#quality-control-of-dnarna",
    "href": "planning-for-submission.html#quality-control-of-dnarna",
    "title": "Planning for submission",
    "section": "Quality control of DNA/RNA",
    "text": "Quality control of DNA/RNA\nYour DNA or RNA samples will need to pass certain quality cut-offs for sequencing, which the sequencing facility will ask for and will have thresholds they require upon submission (e.g., see the Otago Genomics Facility requirements here). After you have done your extractions in the lab, you should perform QC with:\n\nA spectrophotometer (e.g., NanoDrop, DeNovix), which will give you a good indication of the purity/contamination of your sample through 260/280 and 260/230 ratios. This method is not very reliable for determining concentration of your nucleic acid.\nA fluorescent-based quantification method (e.g., Qubit), which will give you a very accurate indication of concentration of your nucleic acid (but not of any contaminants).\nA fragment analysis instrument (e.g., Agilent 2100 Bioanalyzer, Agilent 5300 Fragment Analyzer or Agilent TapeStation), which you can think of like a high-tech agarose gel. It will give you a good indication of your 28S/18S ratio for RNA (this is used to determine the overall RIN - RNA integrity number) or your fragment size distribution for DNA.\n\nTogether, these will give you an almost complete picture of your sample, ready for sequencing. Note that if your samples are below threshold quality, there are protocols that can allow for lower quality or degraded samples. Ideally, this should only be done if there is no option to re-extract, re-purify or repeat the experiment.",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#sequencing-libraries",
    "href": "planning-for-submission.html#sequencing-libraries",
    "title": "Planning for submission",
    "section": "Sequencing libraries",
    "text": "Sequencing libraries\nThe first thing that needs to be done for Illumina, PacBio or Oxford Nanopore (ONT) sequencing is to turn the DNA or RNA sample into something called a library. This converts the raw nucleic acids into a form that the sequencer can actually read. This is generally done by the technician that will also sequence your samples, but some labs may do library prep in-house (i.e., you may do it yourself!). Nanopore is a little different, in that it can sequence native RNA directly, with minimal prep before sequencing. DNA library preparation for ONT sequencing is also generally simpler than for Illumina and PacBio. This is because the technology used to sequence the DNA/RNA using ONT is quite different to how Illumina and PacBio achieve it‚Äìmore on that in the next section on flow cells and sequencing platforms 101\n\n\n\n\n\n\nIllumina lib prep molecular workflow diagram\n\n\n\n\n\n\n\n\n\nLibrary preparation (for Illumina and PacBio) generally involves the following steps, and takes 1-2 days in the lab:\n\n(Optional) Target enrichment / RNA selection\nSelectively enriching for your target molecule (e.g., for standard RNAseq you likely will do polyA capture).\n\n(RNAseq only) Converting your RNA into cDNA using reverse transcriptase.\n\nFragmentation (if needed) Some kits fragment RNA before reverse transcription, others fragment cDNA/DNA after.\nThis ensures fragments are the right size for the platform (e.g., ~200‚Äì400 bp for Illumina).\nEnd repair and A-tailing\nEnds are cleaned up so adapters can be ligated efficiently.\nAdapter ligation\nAdapters are short sequences that enable library binding to the flow cell (Illumina) or capture for SMRTbells (PacBio).\nSome kits combine this with indexing.\n\n\n\n\n\n\n\nPacBio lib prep - SMRTbell adapters\n\n\n\n\n\n\nNote: the SMRTbell technology allows HiFi (high fidelity) long read sequencing. The DNA becomes circularised, which allows the polymerase to make repeated passes around the DNA and the consensus sequence therefore has a higher accuracy than single pass sequencing.\n\n\n\n\nIndexing (barcoding)\nIndices allow multiple samples to be pooled together and sequenced on the same flow cell, then computationally separated afterward (called mulitplexing and demultiplexing).\nSize selection / cleanup\nTypically done with magnetic beads to remove adapter dimers and select the desired fragment range.\nLibrary amplification (if required)\nSome protocols use PCR to enrich adapter-ligated molecules; others (e.g., some PacBio) are PCR-free.\nFinal QC and quantification\nUsing Qubit, Bioanalyzer/Tapestation/Fragment Analyzer, etc. This step ensures your library meets sequencing requirements.\n\n\n\n\n\n\n\nBioanalyzer trace of final library (Illumina mRNA lib prep)\n\n\n\n\n\n\n\n\n\nThere are different library prep methods (i.e., protocols) for each platform that you will also need to chose. This will depend on a few things, such as:\n\nThe quality of your RNA/DNA (e.g., high-quality RNA allows polyA selection; degraded samples may require ribo-depletion or specialised kits).\n\nThe species/tissue type you extracted your RNA/DNA from (e.g., plants have rRNA types that require plant-specific depletion kits, some tissues have high mitochondrial RNA content).\n\nThe type of analysis you want to do i.e., what is your research question\n\nFor example, if you are doing a ‚Äòstandard‚Äô Illumina RNA sequencing project (e.g,. you plan to do differential gene expression analysis to compare different samples), a common choice is Illumina stranded mRNA library prep, which uses polyA selection to capture mRNA. However, you may chose Illumina total RNA library prep with ribo-depletion, which is more expensive, but it has some advantages such as: it can capture non-polyadenylated RNAs (more comprehensive RNA profile) and and is a better option if your samples are partially degraded (it can also handle FFPE samples).\n\nDISCUSSION üí¨\n\n\n\n\n\n\nWhy do you think polyA capture is used for ‚Äòstandard‚Äô RNAseq?\n\n\n\n\n\nMature mRNAs have polyA tails, which can be selectively isolated using oligo DT coated beads that bind mature RNAs only. All other non-polyadenylated nucleic acids and cellular debris can then be washed away.\n\n\n\n\n\n\n\n\n\nWhy do you think we bother adding ‚Äúindex‚Äù sequences to libraries at all? Why not sequence each sample separately?\n\n\n\n\n\nIndexing (barcoding) allows multiple samples to be pooled in a single sequencing run. This massively reduces cost and time. Because each library carries a unique index, the sequencer can mix them together, and downstream software can computationally separate (demultiplex) them accurately afterward.\n\n\n\n\n\n\n\n\n\nWhy do you think size selection is such an important step? What would happen if we skipped it?\n\n\n\n\n\nSize selection ensures that fragments fall within the size range the sequencer expects. Without it, you may get:\n\nadapter dimers (which waste sequencing reads as they take up ‚Äòreal estate‚Äô on the flow cell)\ntoo-short fragments (which cluster preferentially, causing over-representation and distorts the data e.g., sequencing may read into adapters or flow cell)\n\ntoo-long fragments (which may not fully sequence or reduce yield)",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#flow-cells-and-sequencing-platforms-101",
    "href": "planning-for-submission.html#flow-cells-and-sequencing-platforms-101",
    "title": "Planning for submission",
    "section": "Flow cells and sequencing platforms 101",
    "text": "Flow cells and sequencing platforms 101\nThe three major sequencing platform and consumables companies are Illumina, PacBio (Pacific Biosystems) and Oxford Nanopore Technologies (ONT). Each make different platforms/instruments that can handle different levels of throughput, but the chemistry and the ‚Äòreading‚Äô of the sequencing is the main point of difference between the three companies.\nA few examples of the different platforms are:\nIllumina\n\nMiSeq\n\nNextSeq\n\nNovaSeq\n\nPacBio\n\nSequel II\n\nRevio\n\nOxford Nanopore Technologies\n\nMinION\n\nGridION\n\nPromethION\n\nA flow cell is the physical surface inside the sequencing machine (or platform) where the actual reading of DNA or RNA occurs. There are different sizes you can chose from, depending on how many reads you need. Although Illumina, PacBio, and ONT all call their consumables ‚Äúflow cells,‚Äù the underlying technologies are very different.\nFor the most part, and in-depth knowledge of how these flow cells work is not needed to get you started with your sequencing project.\nHere are the basic differences:\n\n\n\n\n\n\n\n\n\nFeature\nIllumina\nPacBio (HiFi / SMRT)\nOxford Nanopore (ONT)\n\n\n\n\nHow sequencing works\nSequencing-by-synthesis (fluorescent nucleotides added one base at a time)\nSingle-molecule real-time sequencing (polymerase incorporates fluorescent bases inside ZMWs)\nNanopore sensing (changes in ionic current as DNA/RNA passes through a pore)\n\n\nFlow cell structure\nPatterned flow cell with billions of oligos that form clonal clusters\nSMRT Cell containing millions of Zero-Mode Waveguides (ZMWs)\nMembrane embedded with thousands of protein nanopores\n\n\nWhat binds to the flow cell\nLibraries bind via adapters to oligos ‚Üí amplified into clusters\nA single SMRTbell + polymerase complex loads into each ZMW\nDNA or RNA strand with a motor protein threads into a nanopore\n\n\nSignal detected\nFluorescent signal imaged each cycle\nFluorescent flashes when each base is incorporated\nChanges in electrical current across the pore\n\n\nAmplification?\nYes ‚Äî cluster generation required\nNo ‚Äî true single-molecule reads\nNo (PCR-free), though can use PCR in library prep\n\n\nTypical read length\n100‚Äì300 bp\n10‚Äì25 kb HiFi reads\n10 kb to &gt;100 kb (ultra-long &gt;1 Mb possible)\n\n\nCan sequence native RNA?\nNo ‚Äî convert to cDNA library\nNo ‚Äî convert to cDNA library\nYes ‚Äî direct RNA sequencing\n\n\nStrengths\nHigh accuracy, high throughput, cost-efficient, chemistry highly compatible with different species/tissues\nHighly accurate long reads; excellent for haplotype resolution\nUltra-long reads; portable; real-time analysis; can detect base mods\n\n\nLimitations\nShort reads only\nLower throughput than Illumina; expensive\nHigher raw error rate; pore lifetime limits yield and susceptible to clogging\n\n\nBest used for\nStandard RNA-seq (DGE); de novo transcriptomes; high-depth short-read assays; metagenomics; error-correcting long reads\nGenome assembly (chromosome-level with HiFi); full-length RNA (Iso-Seq for isoforms); structural variant detection\nField-based sequencing (e.g, rapid microbial identification); genome assembly; native RNA including modification detection (e.g., methylation)",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#decision-points",
    "href": "planning-for-submission.html#decision-points",
    "title": "Planning for submission",
    "section": "Decision points ü§î",
    "text": "Decision points ü§î\nChoosing a platform to do your sequencing comes down to the question you are trying to answer. See the last row in the table above ‚ÄòBest use for‚Äô for some examples of why you might pick one platform over another!\nWhen you get in contact with a sequencing facility, the question they will ask you is not how many samples are you sequencing, but rather, how many reads do you need? This will determine what size flow cell you need, and to some extent, which platform you will use, as different platforms have different capacity (e.g,. Illumina NextSeq is a ‚Äòmedium throughput‚Äô platform, NovaSeq is a ‚Äòlarge throughput‚Äô platform). The number of reads you need scale with the size of the genome and/or complexity of your transcriptome.\nAs a general rule of thumb, for transcriptome sequencing you will need:\nTable 1: Reads per sample\n\n\n\nPurpose / Type\nApprox reads per sample\n\n\n\n\nGene expression profiling\n5‚Äì25 million\n\n\nComplete expression + alternative splicing\n30‚Äì60+ million\n\n\nDe novo transcriptome assembly\n~100+ million\n\n\n\n\n\nThe next thing the sequencing facility will ask you if you are doing short-read sequencing (Illumina) is do you want single-end or paired-end reads. This refers to whether you want a single read (read 1), sequenced from only one end of the library molecule (fragment), or if you want two reads per library molecule (read 1 and read 2, antisense and sense strands). Paired-end costs more, but gives you more resolution.\nThere are pros and cons to choosing either chemistry:\nTable 2: Single-end vs paired-end chemistry (short-read Illumina sequencing)\n\n\n\n\n\n\n\n\nChemistry\nPros\nCons\n\n\n\n\nSingle-end (SE)\nLower cost, fewer reads required (may be able to do more samples); sufficient for basic gene-level DGE\nLimited splice/isoform resolution; less confident mapping when mapping to a genome\n\n\nPaired-end (PE)\nBetter alignment; improved splice junction and isoform detection; more robust for complex transcriptomes or de novo transcriptome assembly\nHigher cost; ~2√ó sequencing required (two reads per fragment)\n\n\n\n\n\nLastly, if you are doing short-read sequencing (i.e., Illumina), the sequencing facility will ask you what read length you want. You can typically chose from between 50bp-300bp (platform-dependent). The choice between a lower or higher read length will be a balance of cost (higher read length = higher cost) and the level of information you need (complex, novel or de novo transcriptomes require higher read lengths; more straight forward analyses with well-annotated genomes can utilise lower read lengths). In contrast, for long-read sequencing platforms (ONT and PacBio), you do not specify a fixed read length. Instead, reads are generated as single, continuous sequences, and their length is determined by the size of the input molecules, the library preparation method, and the sequencing chemistry.\nChoosing a read length is a trade-off between cost, and the amount of information you will recover:\nTable 3: Read length (short-read Illumina sequencing)\n\n\n\n\n\n\n\n\nRead length\nPros\nCons\n\n\n\n\n50 bp\nLowest cost; highest sample multiplexing; sufficient for basic gene-level DGE in well-annotated genomes\nPoor isoform and splice junction resolution; higher multi-mapping\n\n\n100 bp\nGood balance of cost and information; reliable splice junction detection; widely used for standard RNA-seq\nSlightly lower throughput than 50 bp; may miss very complex isoforms\n\n\n150 bp\nImproved isoform resolution; better mapping across repetitive regions; useful for novel transcript discovery\nHigher cost; fewer reads per run\n\n\n300 bp\nMaximum per-read information; helpful for de novo transcriptome assembly\nRarely necessary for Illumina RNA-seq; expensive; reduced throughput\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE #1 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (15 mins)\n\n\n\nExample RNAseq scenario:\nYou are working on a mouse model of cancer genomics. You want to do differential gene expression analysis to compare tumour samples to non-cancerous control tissue, to see if you can find genes that are up or down regulated in the cancerous tissue. You have 40 RNA samples, and since your species has a high-quality reference genome and annotation (i.e., mouse: Mus musculus), you know you have a ‚Äúgood‚Äù genome assembly and annotations to map your sequencing data back to (more on ‚Äúgood‚Äù genomes later!). The mouse genome is ~2.7 Gb (= 2,700,000,000 bp), diploid, with ~20,000 protein-coding genes.\nYou are particularly interested in alternative splicing and novel splice junctions, as you suspect that cancer-associated genes are often regulated at the isoform level.\nYou will sequence your samples at the Otago Genomics Facility, and see on their website they have an Illumina MiSeq and an Illumina NextSeq 2000.\n\n\n\n\n\n\nWhich platform will you chose?\n\n\n\n\n\nThe Illumina NextSeq 2000 is a ‚Äòmedium‚Äô sized short read sequencing platform, ideal for standard RNAseq, and is well-suited to this project. It can output up to 540Gb.\nThe Illumina MiSeq is a ‚Äòsmall‚Äô sized short read sequencing platform, better suited to QC or amplicon sequencing, and can output up to 30Gb. It is too small for this project.\nIllumina benchtop sequencing platforms comparison\n\n\n\nNext you need to decide how many reads you need.\nBased on table 1 above, how many reads do you need per sample?\n\n\n\n\n\n\nReads per sample choice:\n\n\n\n\n\nYou decide you need 30 million reads per sample. You pick the lower end of the scale, as you suspect the genes you are most interested in will be highly expressed, and don‚Äôt expect your tissue to have a particular high transcript diversity that would require more reads.\nYou work out what minimum output you need from the flow cell:\n30 mil reads * 40 samples = 1200 million reads (1.2B).\n\n\n\nNow you need to decide if you want paired-end or single end reads.\nBased on table 2 above, what would you pick?\n\n\n\n\n\n\nPaired-end vs single end choice:\n\n\n\n\n\nPaired-end sequencing will give better detection of novel isoforms and splice junctions.\nThis doubles the number of reads generated per fragment and will give you better resolution.\n\n\n\nYou now need to decide which read length you need. Given the mouse genome is well-annotated, but you are looking for potentially novel isoforms, which read length would you pick, based on table 3?\n\n\n\n\n\n\nRead length choice:\n\n\n\n\n\n50 bp would be a good choice for a well-annotated genome like mouse for standard RNAseq, but does not suit this experiment, as you are looking for novel isoforms/alternative splicing.\n100bp is probably the best choice, balancing cost with novel isoform discovery.\nYou could also chose 150bp, if you want to be sure you‚Äôd capture novel isoforms, especially if they are quite long or complex genes - and don‚Äôt mind a higher cost.\n\n\n\nYou are now ready to pick your flow cell. Check out the Illumina NextSeq2000 flow cell specifications and chose which flow cell will suit this project best. There are four flow cells in ascending output size you can choose from: P1, P2, P3 and P4.\n\n\n\n\n\n\nWhich flow cell will you pick?\n\n\n\n\n\nBased on paired end sequencing using 100bp read length (i.e., 2 x 100bp):\nTotal reads needed for your experiment: 1.2 billion reads.\nCalculation: 1.2 billion reads x 100 (bp) x 2 (PE) = 240 Gb (240 gigabase pairs, or 240 billion individual DNA bases sequenced).\n\nP1 ‚Üí No 100bp option and way too low\n\nP2 ‚Üí 80 Gb (too low for 1.2B demand)\n\nP3 ‚Üí 240 Gb (fits 1.2B reads requirement exactly - best choice!)\n\nP4 ‚Üí 360 Gb (oversized for this project)\n\nNote: the maximum output stated for the flow cell is under optimal conditions, so the P3 flow cell choice just fits, but it is possible you will have less reads then anticipated (e.g., instead of 30 mil reads per sample, you may get 28 mil per sample).\n\n\n\nCongratulations! You are now ready to sequence your RNAseq samples.\n\n\n¬†\nNow let‚Äôs look at DNA sequencing in more detail.\nDNA sequencing may refer to whole genome, whole exome, or targeted sequencing approaches. FILL in a bit more here by someone who knows DNAseq better\nFor Genome sequencing you will need:\n\n\n\n\n\n\n\n\n\nGenome size\nExample species\nApprox genome size\nApprox reads per sample\n\n\n\n\nTiny\nVirus\n&lt;0.1 Mb\n0.1‚Äì0.5 million\n\n\nSmall\nBacteria\n5 Mb\n5‚Äì10 million\n\n\nMedium\nYeast\n12 Mb\n10‚Äì20 million\n\n\nLarge\nFruit fly (D. melanogaster)\n175 Mb\n50‚Äì100 million\n\n\nVery Large\nHuman\n3 Gb\n600‚Äì1,200 million\n\n\nHuge\nWheat\n16 Gb\n6‚Äì12 billion\n\n\n\nWhere Mb = megabase pairs (i.e., 1 Mb = 1,000,000 bp)\nCoverage. talking about average coverage - really repetitive regions can have very low covergae, other more easily resolved sections will have higher coverage.\nheterozygosity homozygosity.\nhaplotypes etc.\nStick mostly to decision points - not a huge lecture/tutorial on genome/ DNA biology. Assume learners haev a genetics background - they just have not yet translated that knowledge into a practical application of NGS.\n\n\n\n\n\n\n\n\nEXERCISE #2 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (10 mins)\n\n\n\nExample DNAseq scenario:\nYou are want to de novo assemble the genome of the New Zealand swamp maire (Syzygium maire), a critically-endangered, endemic myrtaceae species, which is under threat from the pathogen myrtle rust.\nBased on genome sizes of related Syzygium and Myrtaceae species (e.g., Syzygium aromaticum ~370 Mb, S. grande ~405 Mb), you expect the S. maire genome to be on the order of ~350‚Äì400 Mb.\nDe novo genome assembly requires long read sequencing to resolve the longest contiguous sequences possible (ideally the full chromosome length, but that is often not easy or possible to achieve!).\n\n\n\n\n\n\nWhich long-read sequencing platform should you chose?\n\n\n\n\n\nThere are two long-read platforms ‚Äì PacBio and ONT. PacBio better for throughput (amount of reads you can get back) and for accuracy than than ONT? Ask someone who knows this to fill in.\n\n\n\nBalkwill et al. 2024. Tree Genetics & Genomes.\nThe authors also used Illumina sequencing in this paper. What did they use it for? Why do you think they chose to do Illumina sequencing for these samples rather than PacBio?\n\n\n\n\n\n\nSolutions:\n\n\n\n\n\nAnswer: 30 x samples at low coverage for resequencing.\nAnswer: cost, accuracy at SNP level. dont need to resolve full genomes as that was not their question.\n\n\n\n\n\n\n\n\nNote 1: Batch variation. Are you doing all your samples in one batch, or will you have multiple batches? Technical variation can occur, so you may want to wait and do all samples at once on one larger flow cell, or make sure you randomise samples across sequencing batches.\n\n\nNote 2: DNAseq vs RNAseq. You may have noticed we call it ‚ÄòRNAseq‚Äô, even though we convert the RNA into DNA before sequencing! By convention, this is still called RNAseq, to differentiate it from true DNAseq.",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "planning-for-submission.html#nz-sequencing-facilities-and-services",
    "href": "planning-for-submission.html#nz-sequencing-facilities-and-services",
    "title": "Planning for submission",
    "section": "NZ sequencing facilities and services",
    "text": "NZ sequencing facilities and services\n\nCurrent as of: December 2025\n\nSequencing facilities which offer NGS services:\nOtago Genomics Facility (OGF)\nLocation: The University of Otago, Biochemistry Building.\n\nIllumina NextSeq 2000\n\nIllumina MiSeq\nONT P2 Solo\n\nONT MinION\nNanoString nCounter Analysis System (non-NGS)\n\nPerforms: Moderate to large scale RNAseq, DNAseq, amplicon seq etc\nMassey Genome Service (MGS)\nLocation: Massey University\n\n2 x Illumina MiSeq\n\nApplied Biosystems 3500xl capillary instrumentation (non-NGS).\n\nPerforms: small scale RNA or DNAseq, single gene (Sanger sequencing)\nAuckland Genomics\n\nplatforms: Illumina and ONT. They don‚Äôt list on their website which ones they have.\n\nProcotocol available - dont want to go into too much detail but becoems another decision point. Massey offer TruSeq lib prep. Auckland uses the newer kit. (slightly higher input required than the newer chemistry, both are very robust options. Newer one is supposed to be faster and better for more degarded RNA. Higher multiplexing for new kit 384 vs 96 for truseq).\nSee here for comparison between Illumina TruSeq stranded and Illumina stranded mRNA kits\nNon-service platforms around New Zealand:\nAgResearch\n- GenomNZ https://www.agresearch.co.nz/products-and-services/genomnz/ (Invermay) have a NovaSeq - they will do it if they have time and you ask nicely. They are a commercial animal DNA genotyping laboratory.\nLincoln\n- have MGI - compatible with Illumina libraries. not on website.\nother\nCustom science (supplier, does not do the sequencing for you)\n\nNew PacBio Revio in Auckland\n\n\nworking with NZ seq facilities\nstuff on submission process, show example form ?\nhow do you get data back from them ? how do they transfer it?\nOGF gives you data back demultiplexed. I assume all other services in NZ do this too?\nDo anyone use basespace to share reads with people?",
    "crumbs": [
      "Planning for submission"
    ]
  },
  {
    "objectID": "data-storage-and-management.html",
    "href": "data-storage-and-management.html",
    "title": "Genomic data storage and management",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#genomic-data-files",
    "href": "data-storage-and-management.html#genomic-data-files",
    "title": "Genomic data storage and management",
    "section": "Genomic data files",
    "text": "Genomic data files\nGenomic data files are huge, and for one project you will often have several hundred gigabytes (GB) to sometimes terabytes (TB) of data (more on the actual genomic file types in the next section Data wrangling and processing). You most likely won‚Äôt be able to store and analyse these on your local computer, or transfer the files in the ‚Äòtraditional‚Äô way using portable USB drives, so you‚Äôll need to make use of a high capacity storage (HCS), high performance computing (HPC), and file transfer protocols (FTP). An introduction to genomics is also an introduction to the world of high performance computing!\nCaveat: small genomes such as from bacteria often can be transferred, stored and analysed on your local computer.\nYou have a few options of how you want to store and analyse your data, which may be through HPC/HCS services offered by your University or Institute, or through the national computing and digital network REANNZ.",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#research-and-education-advanced-network-new-zealand-reannz",
    "href": "data-storage-and-management.html#research-and-education-advanced-network-new-zealand-reannz",
    "title": "Genomic data storage and management",
    "section": "Research and Education Advanced Network New Zealand (REANNZ)",
    "text": "Research and Education Advanced Network New Zealand (REANNZ)\nREANNZ is ‚Äú..a Crown-owned membership organisation that powers Aotearoa‚Äôs research and education network. Launched in 2007, their high-performance national digital network (or NREN) helps members collaborate and contribute to data-intensive and complex science and research initiatives ‚Äì both here in New Zealand and across the globe.‚Äù\nThey offer many products and services ‚Äì check out their website here ‚Äì but here we will focus on their HPC platform that you may chose to use to analyse your data.\nProjects on REANNZ\nTo use the HPC services, you first need to make or be listed as a member on a ‚ÄòProject‚Äô. A ‚ÄòProject‚Äô will have a code (e.g., nesi03181 or uoo00431) and will need to be linked to a funding source to charge back compute resources used. Multiple people can use one Project; this is often the preferable way to use a Project when collaborating on the same dataset or project. You‚Äôll need to discuss whether you need your own Project, or can be added to an existing Project, with whoever is supplying the funding (most likely your PI / supervisor).\nEither way, first make your own account using your institutional details by logging in here: https://my.nesi.org.nz/.\n\nFrom there, you can apply/access/view your Projects, and manage the compute resource allocation of the Project.\nOnce you have an account and a Project, you can start using the HPC by logging in to Open OnDemand here: ondemand.nesi.org.nz\n\nOnce logged in, you‚Äôll see an app-based dashboard.\nClick on ‚ÄòJupyter Lab‚Äô and then you can chose a few different settings before launching. For the most part, you will only need to change the Project Code and the number of hours you need the session open. You can leave the number of cores and memory per job as the default lowest settings.\n\nOnce the session is open, you can interact with your files through the directory structure on the left, and open either a Terminal or various other scripting programs through the Launcher. More on using the Terminal (also known as shell / unix shell / bash) in the next lesson.\nFor each Project, you will have a nobackup and a project directory. Keep your raw files in the project directory and do your analysis in the nobackup directory. As you can guess by the name, this directory is not backed up, and is best used for working analyses. Additionally, files not modified after 90 days are auto deleted. Final analysed files and imprortant scripts should be copied into the project directory once you have completed your analysis. You may be surprised by how many intermediate files you make and how much ‚Äòtinkering‚Äô you do during your analyses‚Äìmaking use of the two directories helps keep your file system tidier.\n\nNote: It can be a good idea to back-up raw genomic files on a HCS / reannz freezer?\n\nGetting your genomic files on to the REANNZ cluster\nHow do we actually get the genomic sequence files from the sequencing facility to the REANNZ cluster?\nFILL IN HERE\nGLOBUS\nWant more info?\n\nREANNZ provide extensive documentation on how to use their High Performance Computing (HPC) platforms.\n\n\nIn July 2025, the New Zealand eScience Infrastructure (NeSI) was integrated into REANNZ. You may have heard of NeSI before, but if not, it is good to be aware of the name, as you‚Äôll see some legacy branding in the REANNZ documentation or log-in platform (e.g., my.nesi.org.nz is still in use).",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#aoraki-at-the-university-of-otago",
    "href": "data-storage-and-management.html#aoraki-at-the-university-of-otago",
    "title": "Genomic data storage and management",
    "section": "Aoraki at the University of Otago",
    "text": "Aoraki at the University of Otago\nIf you are a University of Otago staff or student, you can use the ‚ÄúAoraki‚Äù HPC cluster. Like REANNZ, you will also connect to the cluster through an Open OnDemand app-based interactive web page.\nhttps://rtis.cspages.otago.ac.nz/research-computing/cluster/index.html",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#other-universities-hpchcs-options",
    "href": "data-storage-and-management.html#other-universities-hpchcs-options",
    "title": "Genomic data storage and management",
    "section": "Other universities HPC/HCS options?",
    "text": "Other universities HPC/HCS options?\nAuckland?",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#ethical-data-management",
    "href": "data-storage-and-management.html#ethical-data-management",
    "title": "Genomic data storage and management",
    "section": "Ethical data management",
    "text": "Ethical data management\n\nFAIR and CARE\nIn 2016, the FAIR principles were published in Scientific Data. These guidelines set to provide a standard through which to improve digital assets:\n\nFindability\n\nAccessibility\n\nInteroperability\n\nReuse\n\nPart of conducting FAIR research is having a reproducible research pipeline. One way this can be done is by documenting your work on a version control system like GitHub. See our GA workshop for more on Reproducibility with Git and Quarto.\nOpen science advocates have embraced this FAIR framework, while others critise its lack of protection of data, for not considering the rights and interest of those that should hold governance over data, in particular, indigenous peoples. In response to this, the CARE framework has also been proposed by Global Indigenous Data Analysis, to complement the existing FAIR principles:\n\nCollective benefit\n\nAuthority to control\n\nResponsibility\n\nEthics\n\n\nThis story ‚ÄúOpen with care; Indigenous researchers and communities are reshaping how Western science thinks about data ownership‚Äù is an interesting read on these perspectives.\nThe Aotearoa Genomic Data Repository (AGDR) and Rakeiora platform are examples of services that have adopted these CARE principles.\n\n\nAotearoa Genomic Data Repository (AGDR)\nFrom the AGDR website:\n‚ÄúThe Aotearoa Genomic Data Repository provides secure within-nation storage, management and sharing of non-human genomic data generated from biological and environmental samples originating in Aotearoa New Zealand. This resource has been developed to follow the principles of MƒÅori Data Sovereignty, and to enable kaitiakitanga (guardianship), so that iwi, hap≈´ and whƒÅnau (tribes, kinship groups and families) can effectively exercise their responsibilities as guardians over biological entities that are taonga (precious or treasured). While the repository is designed to facilitate the sharing of data ‚Äî making it findable by researchers and interoperable with data held in other genomic repositories ‚Äî the decision-making process regarding who can access the data is entirely in the hands of those holding kaitiakitanga over each data set.‚Äù‚Äù\nThe AGDR is enabled by MBIE funding to Genomics Aotearoa.\n\n\nRakeiora Genomics platform\nThe Rakeiora Genomics Platform is designed to enable and test pilot precision medicine research, linking genomics and health.\nThey have chosen a walled garden approach to this infrastructure.\n‚ÄúThis means that all genomic data and health data, and its analysis, are undertaken only within this computational environment ‚Äì the data never leave and are certainly never downloaded to a researcher‚Äôs own computer or a hospital clinical laboratory computer‚Ä¶\n‚Ä¶Its modular nature will allow linkage (with consent) to other health data systems currently under development in Aotearoa New Zealand. This approach in particular addresses transparency of use and control over narratives. Lack of these features in other precision medicine platforms worldwide has led to significant problems for patients and research participants, including indigenous communities; learning from these negative experiences is key to avoid repeating them.‚Äù ‚Äì From the Genomics Aotearoa website.",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "data-storage-and-management.html#public-data",
    "href": "data-storage-and-management.html#public-data",
    "title": "Genomic data storage and management",
    "section": "Public data",
    "text": "Public data\nYou are probably familiar with using the NIH NCBI database, hosted by the United States Government, for things such as BLAST searches and literature searches.\nNCBI has a repository called the Sequence Read Archive (SRA), which is where a large proportion of genomic data from all over the world is stored, as publicly available raw, high-throughput, sequencing data.\nIf your data has no ethical concerns, this can be a great resource for making your data freely available and easily citeable in publications.\nHere we will not go into detail on how to either download or upload data to the SRA (see documentation on their website). But some points to be aware of are:\n\nA BioProject is a way to link all the sequencing and biological data together under one umbrella (as a general rule, 1 publication = 1 BioProject, but many groups use a single BioProject for multiple publications). If you are uploading your own data, we recommend starting with creating a BioProject, which will then give you a single accession (e.g., PRJNA31257) to use for the next steps (BioSample + SRA raw read uploads).\nA BioSample is a unique descriptor of the biological source material (e.g, all the biological metadata of your sample ‚Äì species, sex, age, location, tissue). This is often (but not strictly) set up as 1 BioSample = 1 library. Each BioSample accession will be linked to the matching sequence data in the SRA, and all housed under one BioProject accession number.\n\nEqually, if you are downloading data from the SRA, you can make use of BioProject and BioSample accessions to identify and orientate yourself to the data.\nExample BioProject:\n\n\n\n\n\n\nHuman airway smooth muscle transcriptome study\n\n\n\n\n\nYou can see there are 16 SRA experiments and 16 BioSamples ‚Äì you can guess that these probably match one to one.\nThere are also GEO datasets (Gene Expression Omnibus) associated with this study, which are repositories for functional genomic data. These are a more processed form of the data e.g., count tables and differential expression data.\n\n\n\n\n\nThis is not the only public repository of sequence reads, some other examples include: European Nucleotide Archive (ENA) and the DNA data bank of Japan DDBJ Sequence Read Archive (DRA). These data banks are linked together via the International Nucleotide Sequence Database Collaboration. NCBI also details some of the collaborative projects here (e.g., The Taxonomy Project, The Feature Table).",
    "crumbs": [
      "Genomic data storage and management"
    ]
  },
  {
    "objectID": "organisation-tidiness.html",
    "href": "organisation-tidiness.html",
    "title": "Organisation and tidy data",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Organisation and tidy data"
    ]
  },
  {
    "objectID": "organisation-tidiness.html#metadata",
    "href": "organisation-tidiness.html#metadata",
    "title": "Organisation and tidy data",
    "section": "Metadata",
    "text": "Metadata\nWhen we think about the data for a sequencing project, we often start by thinking about the sequencing data that we get back from the sequencing centre. However, equally or more important is the data you‚Äôve generated about the sequences before it ever goes to the sequencing centre. This is the data about the data, often called the metadata. Without the information about what you sequenced, the sequence data itself is useless.\n\n\n\n\n\n\nEXERCISE üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (3 mins)\n\n\n\nWhat kind of data and information have you generated (or think you will generate) about your samples that can be considered metadata? How do you store this information?\nDiscuss with the group.\n\n\n\n\n\n\nSOLUTIONS\n\n\n\n\n\n\nExperimental conditions describing the biological samples, such as: temperature, weight, length, treatment.\nLaboratory/technical data, such as: protocol or kit used to extract DNA/RNA, specific processing equipment, concentrations or quality indicators (e.g., Nanodrop, Qubit, or Bioanalyzer results)\n\nLab notebook notes about how you conducted those experiments.\n\nSpreadsheet or tabular data with the data from your experiment and whatever you were measuring for your study.",
    "crumbs": [
      "Organisation and tidy data"
    ]
  },
  {
    "objectID": "organisation-tidiness.html#structuring-data-in-spreadsheets",
    "href": "organisation-tidiness.html#structuring-data-in-spreadsheets",
    "title": "Organisation and tidy data",
    "section": "Structuring data in spreadsheets",
    "text": "Structuring data in spreadsheets\nRegardless of the type of data you‚Äôre collecting, there are standard ways to enter that data into the spreadsheet to make it easier to analyse later. We often enter data in a way that makes it easy for us as humans to read and work with it, because we‚Äôre human! Computers need data structured in a way that they can use it. So to use this data in a computational workflow, we need to think like computers when we use spreadsheets.\nThe cardinal rules of using spreadsheet programs for data:\n\nLeave the raw data raw - do not change it!\n\nPut each observation or sample in its own row.\n\nPut all your variables in columns - the thing that vary between samples, like ‚Äòstrain‚Äô or ‚ÄòDNA-concentration‚Äô.\n\nHave column names be explanatory, but without spaces. Use ‚Äò-‚Äô, ‚Äô_‚Äô or camel case instead of a space. For instance ‚Äòlibrary-prep-method‚Äô or ‚ÄòLibraryPrep‚Äôis better than ‚Äôlibrary preparation method‚Äô or ‚Äòprep‚Äô, because computers interpret spaces in particular ways.\n\nDo not combine multiple pieces of information in one cell. Sometimes it just seems like one thing, but think if that‚Äôs the only way you‚Äôll want to be able to use or sort that data. For example, instead of having a column with species and strain name (e.g.¬†E. coli K12) you would have one column with the species name (E. coli) and another with the strain name (K12). Depending on the type of analysis you want to do, you may even separate the genus and species names into distinct columns.\n\nExport the cleaned data to a text-based format like CSV (comma-separated values) format. This ensures that anyone can use the data, and is required by most data repositories.\n\n\n\n\n\n\n\n\nEXERCISE üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (2 mins)\n\n\n\nAbove is some potential spreadsheet data generated about a sequencing experiment.\nDiscuss some of the problems with the spreadsheet data shown above. You can look at the image, or download the file to your computer via this link and open it in Excel.\n\n\n\n\n\n\nSOLUTIONS\n\n\n\n\n\nHere is a clean version of the data (download link here). Note the following changes to make the data tidy:\n\nSections reordered to be in single columns\n\nRemoved formatting/colours which won‚Äôt be interpreted by most computational tools\n\nHeader information about the reference, facility, read length etc moved to their own columns\n\nSpaces replaced in column names with _\nStandarised language for mutator and cit columns i.e., \"+\" became plus\n\nData has also been saved as a tsv file rather than excel format.\n\n\n\n\n\n\n\n\nTidy data principles\nBest ways to name columns:\n\nBe careful of zero values versus missing values:",
    "crumbs": [
      "Organisation and tidy data"
    ]
  },
  {
    "objectID": "outtakes-notes.html",
    "href": "outtakes-notes.html",
    "title": "Outtakes and notes",
    "section": "",
    "text": "WORK IN PROGRESS\n\n\n\n\n\n\nOuttakes and notes\nNon-NGS sequencing around New Zealand:\nLincoln\n- DNA sequencing service (Sanger)\nOtago - Genetic Analysis Service (GAS) (Sanger)\ngo back over genmic data carpentry from the carpentries to see what else they go over.\nAssembly QC: biological and technical assessments of the three Cs (contiguity, correctness, completeness). from : https://genomicsaotearoa.github.io/BioinformaticsTrainingProgramme/portfolio.html#long-read-genome-assembly\nwhy would you chose internantional seq options over nz, cost, local.\nintro to bioinformatics.",
    "crumbs": [
      "_outtakes/notes"
    ]
  },
  {
    "objectID": "test-styling.html",
    "href": "test-styling.html",
    "title": "test styling",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "_test styles"
    ]
  },
  {
    "objectID": "test-styling.html#header-2",
    "href": "test-styling.html#header-2",
    "title": "test styling",
    "section": "Header 2",
    "text": "Header 2\ntext\n\nHeader 3\ntext\n\nHeader 4\ntext\n\nHeader 5\ntext",
    "crumbs": [
      "_test styles"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#getting-started-with-genomics",
    "href": "index.html#getting-started-with-genomics",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "Getting started with genomics",
    "text": "Getting started with genomics\nThis is a beginner-friendly workshop, designed to get you started with the world of genomics. Whatever you‚Äôre doing‚Äîwhether it‚Äôs transcriptomics, genome assembly, variant calling, metagenomics, or something else‚Äîif you will be using genomic data this workshop is for you!",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#whats-covered-in-this-workshop",
    "href": "index.html#whats-covered-in-this-workshop",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "What‚Äôs covered in this workshop",
    "text": "What‚Äôs covered in this workshop\n\nOrganisation‚Äîfrom messy lab books and excel spreadsheets to tidy, computer-friendly data\n\nWorking with sequencing facilities and understanding genomic data types\n\nData storage repositories, public services and facilities, and principles of FAIR and CARE\nQuality control, wrangling of raw reads and an introduction to genomic terminology",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#whats-not-covered-in-this-workshop",
    "href": "index.html#whats-not-covered-in-this-workshop",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "What‚Äôs NOT covered in this workshop",
    "text": "What‚Äôs NOT covered in this workshop\n\nNon-NGS sequencing and services (e.g., Sanger sequencing, qPCR, genotyping, probe-based applications such as microarrays and NanoString nCounter)\n\nGenomic analysis pipelines (beyond the basics of initial quality checks of raw reads)\nThe basics of cluster or HPC resourcing and specialised software (e.g., we do not cover schedulers such as SLURM, partitions/CPUs/GPUs, chosing compute allocation allowance). See our workshop on Introduction to Bash Scripting and HPC Job Scheduler for this.\nUsing shell, beyond the very basics (e.g., we do not cover writing/submitting bash scripts, modules, accessing the cluster using ssh)",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#glossary",
    "href": "index.html#glossary",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "Glossary",
    "text": "Glossary\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nAdapter\nShort synthetic DNA sequence ligated to the DNA molecule during library prep which allows the molecule to bind to the flow cell during sequencing and also provides a primer binding site\n\n\nbp\nBase pair\n\n\nHCS\nHigh Capacity Storage\n\n\nHPC\nHigh Performance Computing\n\n\nIndex\nAlso known as barcode. Short unique sequence added to each DNA molecule in one library, allowing the identification of that library/sample and thereby enabling pooling of the libraries (one run = cheaper).\n\n\nMb\nMegabase pair (1,000,000 bp)\n\n\nMB\nMegabyte\n\n\nMultiplexing\nSequencing multiple samples simultaneously in one run by combining libraries into one pool. Samples (i.e., libraries) are de-multiplexed (separated) in silico usually by the technician, based on unique indices.\n\n\nGb\nGigabase pair (1,000,000,000 bp)\n\n\nGB\nGigabyte\n\n\nNGS\nNext-generation sequencing\n\n\nSE / PE\nSingle-end / Paired-end",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#attribution",
    "href": "index.html#attribution",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "Attribution",
    "text": "Attribution\nParts of this workshop were adapted from and inspired by content from The Carpentries Data Carpentry lessons on Genomics.\n\n\n\n\n\n\nCopyright information:\n\n\n\n\n\nAll Carpentries instructional material is made available under the Creative Commons Attribution license CC BY 4.0. The material in this workshop is not endorsed by the Carpentries and has been adapted by Genomics Aotearoa for our own teaching purposes.\nIn this workshop, the following lessons were adapted from The Carpentries Data Carpentry in the manner stated below:\n\nOrganisation and tidy data section has re-used material from Project Organization and Management for Genomics.\nData Wrangling and Processing for Genomics. Currently not using this workshop but likely to re-use.\n\n\n\n\nOther material used in this workshop:\n\nIllumina library prep molecular workflow diagram in Planning for submission from Illumina Stranded mRNA Prep, Ligation Data Sheet. M-GL-02143 v1.0\n\nBioanalyzer trace of final mRNA library in Planning for submission from Illumina Stranded mRNA Prep, Ligation Protocol Document # 1000000124518 v04.\n\nPacBio SMRTbell adapters image in Planning for submission from Template Preparation and Sequencing Guide P/N 000-710-821-13.\n\nMaterial from our Introduction to Shell workshop is re-used in the Genomic data wrangling and processing section.\n\nDefinitions:\n\nRe-used material: Almost word-for-word, including images, with minor wording or styling modifications.\n\nMinimally-adapted material: Inspired by stylistic choices and general workflow, but material is primarily developed by Genomics Aotearoa.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Genomic Data Carpentry (Aotearoa edition)",
    "section": "",
    "text": "Made with ‚ù§Ô∏è and Quarto",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html",
    "href": "data-wrangling-and-processing.html",
    "title": "Genomic data wrangling and processing",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#command-line-interface-cli-vs-graphical-user-interface-gui",
    "href": "data-wrangling-and-processing.html#command-line-interface-cli-vs-graphical-user-interface-gui",
    "title": "Genomic data wrangling and processing",
    "section": "Command-line interface (CLI) vs graphical user interface (GUI)",
    "text": "Command-line interface (CLI) vs graphical user interface (GUI)\nCommand line interface (CLI) and graphic user interface (GUI) are different ways of interacting with a computer‚Äôs operating system. They have different pros and cons. Most people are familiar with the GUI as it is the default interface for most software, particularly on Windows and Mac OS. When using the GUI, you see and interact with visual representations of files, folders, applications, and most other functions of your computer. When using the CLI, you work largely with text representations of software, files, folders, input and output. The shell is a program that allows you to control your computer by typing instructions on the CLI with a keyboard.\nThere are several reasons to learn how to use the CLI:\n\nFor most bioinformatics tools, there are no graphical interfaces. If you want to work in metagenomics or genomics, you‚Äôre going to need to use the CLI/ shell.\n\nThe shell gives you power and allows you to work more efficiently. Tasks that are repetitive (e.g.¬†renaming hundreds of files) can be automated. Tasks that are tedious (e.g.¬†testing a range of input parameters) can be simplified.\n\nTo use remote computers or cloud computing, you often need to use the shell.\n\nHere we will show you a quick introduction to using the shell to quality check your raw reads. For more on the shell, see our workshops on Introduction to Shell and Intermediate Shell.\n\nNote: you‚Äôll hear the terms ‚Äòshell‚Äô, ‚Äòbash‚Äô, ‚Äòunix‚Äô, ‚Äòterminal‚Äô and ‚Äòcommand-line‚Äô used almost interchangeably. For beginners, you can think of them as essentially all the same thing! As you gain more computational skills, you can dig into the differences.",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#first-check-that-the-data-are-not-corrupt",
    "href": "data-wrangling-and-processing.html#first-check-that-the-data-are-not-corrupt",
    "title": "Genomic data wrangling and processing",
    "section": "First, check that the data are not corrupt",
    "text": "First, check that the data are not corrupt\nBelieve it or not, computers can make mistakes! When your data files are being copied over from the sequencing facility to cloud storage, errors can occur that cause your files to become corrupted. This is not always obvious based on file size or a quick look at the contents. The first thing you‚Äôll want to do is run a checksum, which will output a fixed-length message of 16 bytes‚Äì a unique identifier of each file. The files should also come with the checksums run by the technician at the sequencing facility. Check out the section on Data Integrity in our GA shell workshop for more information on how to run this.",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#understanding-genomic-file-types",
    "href": "data-wrangling-and-processing.html#understanding-genomic-file-types",
    "title": "Genomic data wrangling and processing",
    "section": "Understanding genomic file types",
    "text": "Understanding genomic file types\nThe files you will get back from the sequencing facility will most likely end in .fastq.gz\nThe .gz indicates it is a compressed gzip file. For most genomic analyses, you do not need to unzip these first‚Äìthis saves you storage space, as unzipped files can be double or triple the zipped size!\nThe fastq indicates the file is in FASTQ format. FASTQ files are a text-based format that stores the raw read sequences, along with a quality score for each base.\nThe first 4 lines of a fastq file describe one sequence read:\n\nThe first line is the header information, beginning always with an @. This is the instrument-specific, run identifier and read identifiying information.\n\nV350304715 = instrument-specific\n\nL3 = lane 3 on the flow cell. Can be used for troubleshooting if something globally went wrong with sequencing.\n\nC001 = cluster identifier (can be used for troubleshooting, same as above).\n\nR001 = Read 1. All the reads in this file are read 1. If you have paired-end data, you‚Äôll have a corresponding read 2 file.\n\n00020454 = unique identifier for that read.\n/1 = indicates this is a pair member. Only paired-end data have the /1 or /2 additional identifier.\n\nEach instrument and chemistry will have slightly different header information. The main thing to look out for are indications of the data being read 1 or read 2 (indicates antisense or sense strand data, for protocols that can differentiate strandedness) and whether it is part of a mate pair (indicated by the /1 or /2)\nThe second line is the actual sequence. Count the number of bases ‚Äìwhich read length was chosen for this dataset?\nThe third line is just a ‚Äú+‚Äù. This can be optionally followed by the same sequence identifier (and any description) again.\nThe fourth line is the quality score. Each base in line 2 has a corresponding quality score, indicated by an ASCII character in line 4.\nFrom left to right, these are the quality scores in increasing order of quality:\n!\"#$%&'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\nSo, if a single base has a quality score of !, which corresponds to a Q-score of 0, this indicates exceptionally poor quality. The sequencing machine was not able to resolve which base it should be. Often these will be shown as N‚Äôs.\nConversely, if a single base has a quality score of I, which corresponds to a Q-score of 40, this indicates very high quality. The sequencing machine was ‚Äúvery confident‚Äù that the base called is correct (Q40 indicates an error rate of 0.0001, i.e., a 1 in 10,000 chance of the base being called wrong. I is near the upper end of typically achieved quality values, but higher is possible.\nFor more on quality scores, you can also read this Illumina guide here. Note there are different types of encoding, but you will most frequently encounter Phred+33.\nWe can assess the quality score across all reads using software called FastQC, and trim down reads to remove poorer quality bases below a set threshold (generally with newer sequence data, you can use Q30 or Q40 as a cut-off). We won‚Äôt cover trimming here, see our workshop on RNA-seq Data Analysis for a step-by-step guide.\n\nOther genomic file types\nWe‚Äôve talked about fastq and gz files types, but there are some other common genomic file types you should know about.\nYou should also be aware that the extension on the file type is largely there just so you as a human know what kind of file it is. When using the CLI, the computer does not care what the extension says.\n\n\n\nExtension\nName\nDescription\n\n\n\n\n.fasta or .fa, .fna, .faa\nFASTA, FASTA nucleic acid, FASTA amino acid\nContains sequence data. Each sequence starts with a single header line starting with a &gt;, followed by the nucleotide (or amino acid in case of .faa) sequence on the second line. No quality encoding included.\n\n\n.bam .sam\nBinary/Sequence Alignment Map\nContains alignment information of your reads/sequences that are mapped against a reference sequence (e.g., genome). BAM are the compressed, computer-readable only version; SAM are human-readable but larger files. Somewhat interchangeable file types.\n\n\n.vcf\nVariant Call Format\nContains sequence variants called relative to a reference genome. Split into two sections; the header information and the records. See our Intro R workshop, section on VCF files.\n\n\n.gtf\nGeneral Feature Format\nContains genome annotation data.\n\n\n\n\n\nReal examples:\n\n\n\n\n\n\nFASTA\n\n\n\n\n\nFASTA file containing cds data from a genome, opened in a text editor: \n\n\n\n\n\n\n\n\n\nBAM/SAM\n\n\n\n\n\nadd screenshots!\n\n\n\n\n\n\n\n\n\nVCF\n\n\n\n\n\nVCF file opened in excel: \n\n\n\n\n\n\n\n\n\nGTF\n\n\n\n\n\nGTF file opened in a text editor:",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#fastqc---quality-scoring-of-raw-reads",
    "href": "data-wrangling-and-processing.html#fastqc---quality-scoring-of-raw-reads",
    "title": "Genomic data wrangling and processing",
    "section": "FASTQC - quality scoring of raw reads",
    "text": "FASTQC - quality scoring of raw reads\n\nfastqc in depth (use to teach intro shell )",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  },
  {
    "objectID": "data-wrangling-and-processing.html#good-genome-bad-genome",
    "href": "data-wrangling-and-processing.html#good-genome-bad-genome",
    "title": "Genomic data wrangling and processing",
    "section": "Good genome, bad genome?",
    "text": "Good genome, bad genome?\nYou will often hear geneticists refer (somewhat colloquially) to ‚Äúgood‚Äù and ‚Äúbad‚Äù genome assemblies. But what does this actually mean? And how can you tell whether a species you are working on has a good genome assembly?\nIn practice, we assess genome assemblies using a few metrics that capture contiguity and completeness.\nCommon genome assembly metrics\n\nContiguity is often measured as contig and scaffold N50, which is the length cutoff for the longest contigs that contain 50% of the total genome length. In this era of long-read genome assemblies, a contig N50 over 1 Mb is generally considered good. Excerpt taken from PacBio article.\nAlso see Wiki entry on N50/L50.\nCompleteness is often measured using a BUSCO (Benchmarking Universal Single-Copy Orthologs) score, which measures completeness using sets of conserved, single-copy genes expected to be present in most species within a specified lineage.\n\nReported as percentages of complete, duplicated, fragmented, and missing genes. &lt;- change to example.\nGenome assemblies can be described more qualitatively as (in order of less to more complete):\n\nContig-level ‚Äì sequences are assembled but not ordered or oriented. Often can be thousands to hundreds of thousands of contigs.\n\nScaffold-level ‚Äì contigs linked together, often with gaps. None are placed (i.e., chromosome known) or localised (i.e., orientation on chromosome known).\n\nChromosome-level ‚Äì one or more chromosomes complete, but some unplaced scaffolds may be present.\n\nComplete genome - all chromosomes are resolved with no gaps. Not necessarily telomere-to-telomere (T2T).\n\nSee NCBI Glossary for Assembly level.\n\n\nWhat do we mean by a ‚Äúgood‚Äù genome?\nA good genome assembly is typically one that is:\n\nHighly contiguous\nReads have been assembled into long sequences called contigs, ideally approaching full chromosome lengths.\nBiologically complete\nMost expected genes are present (high BUSCO completeness).\nStructurally accurate\nLarge-scale errors such as mis-joins or collapsed repeats are minimised.\n\n\n\nAssembly quality vs annotation quality\nIt is important to distinguish between:\nGenome assembly i.e., the reconstructed DNA sequence itself, and the Genome annotation, which is the identification and labelling of genomic features, including gene structures (exons, introns, and CDS), non-coding RNAs (e.g., rRNA, tRNA and lncRNA), and associated identifiers such as gene_id, transcript_id, and database cross-references.\nA genome can be well assembled but poorly annotated, or vice versa.\n\nEXERCISES üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (6 mins):\nHow would you describe these genomes? Look at the assembly stats and make some notes of how ‚Äògood‚Äô you think each assembly is.\n\n\n\n\n\n\nEXERCISE #1 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (3 mins) - Human Genome Assembly\n\n\n\nHuman Genome assembly GRCh38.p14\n Note: RefSeq is the curated database. GenBank is the non-curated, anyone-can-submit-to database.\n\nJot down your thoughts before looking at the solution below:\n\n\n\n\n\n\nHuman genome solution\n\n\n\n\n\nChromosome level - very high quality. busco score - very close to complete. very good genome\nnumber of extra scaffolds and contigs is very low (470 s / 996 c - it can be thousands of extra so hundreds is pretty good!)\nscaffold and contig N50. describe these!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE #2 üß†üèãÔ∏è‚Äç‚ôÄÔ∏è (3 mins) - Sea Anemone Genome Assembly\n\n\n\nNematostella vectensis (sea anemone) Genome assembly ASM20922v1\n\n\nJot down your thoughts before looking at the solution below:\n\n\n\n\n\n\nSea anemone solution\n\n\n\n\n\nscaffold level - medium quality. but the N50 is below 1mb, at 472.6kb scaffold. not great! quite fragmented.\nbusco score pretty good despite lack of placed scaffolds. contig/scaffold N50 - high enough that most genes are resolved.\nassembly itself not amazing, but annotation is probably good enough for gene level compariosn with other species.\nLarger scale structural variants and synteny difficult or erroneous to resolve. -&gt; is this true?\n\n\n\n\n\n\nExtra for experts\n\n\n\n\n\nHere is the original paper for the curious: Putnam et al.¬†2007.\nThe authors claim the genome reveals ‚Äúancestral eumetazoan genomic organization‚Äù. How did they assess this and what conclusion did they make about the eumetazoan ancestor resemblance to modern vertebrates, sea anemones and prokaryotes? Do you think they had a ‚Äògood‚Äô enough genome to assess this?",
    "crumbs": [
      "Genomic data wrangling and processing"
    ]
  }
]